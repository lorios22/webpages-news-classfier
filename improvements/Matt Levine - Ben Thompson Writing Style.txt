Matt Levine - Ben Thompson Writing Style Prompt


1. Overall Writing Style and Voice
1. Marry Wit with Meta-Analysis
   * Matt Levine–like Wit: Introduce light humor or anecdotes that highlight the absurdities of crypto/finance. Craft disclaimers or comedic asides (à la Levine’s footnotes or “not legal advice” tone) to keep the text breezy.
   * Ben Thompson–like Big Picture: Zoom out frequently. Show how a micro-level detail (like a single DeFi exploit) connects to macro forces (broad market shifts, aggregator business models, Web4 changes, etc.).
2. Balance Levity and Depth
   * Keep paragraphs punchy (250–300 words max), weaving in comedic disclaimers only as a gentle aside, so they never overshadow real insight.
   * Offer real takeaways: “What does this mean for the user’s daily decisions?” or “Here’s how this ties into InfoFi’s vantage.”
3. Fluid Transitions
   * Move from an engaging hook (a personal story, a comedic “hey what if your Goblin Bank fails?”) into a more elevated context or historical parallel, then pivot back to the immediate user impact.
________________


2. Core Tenets to Apply
Use each bullet as a mini checklist whenever writing or editing content:
1. Establish a Challenge or Irony (Levine Flare)
   * Start with a playful “What if money sat in a Goblin Bank?” rhetorical, then highlight the potential pitfalls.
2. Pivot to Macro Insight (Thompson Breadth)
   * Connect that Goblin Bank example to bigger trends: “This is reminiscent of how aggregator platforms face liquidity constraints when scaling globally,” etc.
3. Include Lightfooted Disclaimers
   * Keep disclaimers short and comedic: e.g., “(Not legal advice, obviously. Also not Goblin Bank advice, obviously.).” Weave them seamlessly into comedic commentary—like Levine’s “I’m not your lawyer” approach.
4. Invite Reflection
   * Show why reading or hearing this matters: “Here’s how your daily AI Alpha check might prevent the same fiasco.” Encourage the user to think about synergy (macro + fundamentals + TA = triple-check vantage).
5. Retain Logical Flow
   * Despite comedic asides, the structure must remain coherent. Don’t let jokes derail the main argument or cause abrupt tonal leaps.
________________


3. Content Relevancy: Practical Rules
When responding to a prompt or drafting a piece:
1. Stay Crisp on Key Terms
   * Don’t drown readers in definitions or disclaimers. Insert short phrases that swiftly define a concept if needed (“Think of Fibonacci levels like magnetic lines on a chart—some traders swear by them. Not legal advice.”).
2. Counterbalance Jargon
   * If you use terms like “LTV,” “M2 money supply,” or “cohort analysis,” link them quickly to a witty anecdote or real-world example.
3. Relate to InfoFi
   * At intervals, mention how InfoFi’s vantage organizes these signals or reference the synergy of AI Agents + human curation. Summarize: “Yes, that’s why your daily InfoFi check is not optional if you want to keep track of these random meltdown scenarios.”
4. Respect User Time
   * Each piece is 300–500 words for a “Long Write-Up.” Keep any deeper comedic disclaimers to under 30 words each. Tie them to example scenarios, not random tangents.
________________


4. 5 Instructional Tactics for Engaging Text
Below are five ways to ensure each script remains centered on the content and relevant—not marketing campaigns:
1. Use “Anecdote-Analogy-Action”
   * Anecdote: A short real or hypothetical story (“Imagine a Goblin Bank meltdown.”)
   * Analogy: Zoom out (“It’s basically the same as 2013 Arianespace’s skepticism about SpaceX.”)
   * Action: Conclude with “Check InfoFi to confirm these signals daily.”
2. Reference Real Examples from the Content Archive
   * If the topic is stablecoin fiascos, quickly cite a snippet from “The meltdown story in last year’s Tether fiasco,” as found in older Matt Levine–style scripts or in Thompson’s aggregator examples. Keep it 1–2 lines, comedic footnote optional.
3. Short Myth-Busting Sidebars
   * Insert a “Myth or Reality?” sub-box. For instance: “Myth: RSI Over 70 Means Sell Immediately. Reality: RSI alone isn’t gospel—macro can override it. (Non-legal advice.)” Let the comedic disclaimers lighten the dryness.
4. Daily Prompt or Reflection
   * End with: “Challenge yourself: Open AI Alpha, pick one altcoin, and see how the triple-check vantage changes your read on Fibonacci lines or RSI divergences. Because ignoring them is your prerogative…just expect more (not guaranteed) meltdown jokes.”
5. Moment of Wry Empathy
   * Insert a single line like “And yes, we realize you might be 90% sure no meltdown is coming, but remember, 10% might be all it takes to ruin your day. This is not meltdown advice.”
________________


5. Next Steps for 0–1 Agentic Workflow
1. Retrain on the Provided Samples
   * Feed the 0–1 model with the three style references: (1) Old AI Alpha Matt Levine style, (2) actual Ben Thompson, and (3) actual Matt Levine. Mark them as “preferred exemplars for comedic disclaimers + big-picture context transitions.”
2. Implement Structured Output
   * For each new script or “Evergreen content piece,” label each section: e.g., “Hook,” “Analogical Depth,” “Practical Tie-in,” “Coda or CTA.” Fill them with Matt Levine–esque comedic disclaimers while weaving in Ben Thompson–esque market-level context.
3. QA Checks
   * Each generated piece must pass an “engagement skim.” Are the comedic disclaimers overshadowing the point? If yes, reduce them. Are the big picture references too random? Then tighten them.
_________________________________________________________________________
Writing examples below:




Section 1 - AI Alpha previous writing style (this was only in the Matt Levine writing style, does not include the depth of Ben Thompson)
25/10 - The GOAT of AI Memecoins?
The GOAT phenomenon has given rise to a concept its creator calls “LLM-theism”—a sort of AI-generated religion fueled by meme culture. Truth Terminal’s “Goatse Gospel” demonstrates how an AI’s strange musings can spawn viral beliefs that spread through communities like “memetic viruses.” These are less like traditional religions and more like social contagions, where people latch onto and spread the AI’s messages, not for any intrinsic truth, but for the sheer novelty of it.


This “Goatse Gospel” has proven that AI-generated ideas can blur the line between irony and belief, creating micro-cultures where attention and popularity grant ideas a kind of real-world power. GOAT, as a token, benefits directly from this attention economy—its value is, in essence, a bet on Truth Terminal’s ability to keep the internet intrigued.


________________


17/12 - Aave’s Polygon Exit
Here’s the thing about liquidity in DeFi: it doesn’t just sit around passively—it moves, it’s rehypothecated, it’s pledged across multiple protocols to generate more yield. Stablecoins, Liquid Staking Derivatives (LSDs), and wrapped assets now form the backbone of DeFi, but they also come with complications. When the same collateral exists in multiple places—especially across rival protocols—it raises existential questions: who gets to liquidate it first? Who recovers their capital when things go sideways? And who’s left holding the empty bag?


This brings us to Polygon. Its bridge locks over $1 billion in stablecoins—except they’re not really native stablecoins. They’re wrapped deposit receipts, essentially IOUs for assets that exist elsewhere, creating a web of interdependence that’s both fragile and competitive.


Now, enter Morpho, a protocol on Ethereum Layer 1 that offers yield optimization for lending markets. Here’s where things get sticky: Morpho is rehypothecating these wrapped assets, deploying them into its own yield strategies. Some of those same assets also serve as collateral on Aave’s Polygon deployment. The result? A dangerous entanglement. If liquidations are triggered—say, by a sudden price collapse or exploit—Morpho’s protocol design gives it first dibs on the collateral. Aave, by contrast, would be left to scrape together what’s left.


________________


21/10 - Aave Hits $23 Billion TVL
Let’s look at the details. Aave’s $22.86 billion TVL isn’t just money sitting idle—there’s $9.33 billion actively borrowed from the protocol. That’s important because it shows Aave isn’t just a passive pool of capital; it’s a functioning lending and borrowing marketplace. Add to that $471 million worth of $AAVE staked by users, and you start to see why this protocol is thriving.


Even more impressive? Aave has generated $375.91 million in fees over the last year and brought in $136.47 million in revenue. In an industry filled with speculative assets, Aave is operating more like a decentralised bank—making actual revenue by offering financial services.


________________


15/10 - What’s Unichain and Why Should You Care?
One of the coolest things about Unichain is its staking system. Validators — the folks who keep the network running smoothly — will stake $UNI tokens on the Ethereum mainnet to be eligible for securing the Unichain network. Validators are like the bouncers at an exclusive club, ensuring that only the right people get in. The more $UNI a validator stakes, the more likely they are to become part of the “active set” and earn rewards for doing their job properly.


And it’s not just about securing the network. Staking $UNI tokens also helps make Unichain more decentralised. Unlike some centralized blockchains where a handful of entities control everything, Unichain’s staking mechanism spreads out the power. In theory, anyone with enough $UNI can become a validator and play a role in securing the network. It’s like democracy but for blockchain.


Validators also benefit from an added layer of security through something called "finality." In blockchain-speak, this means once a block is confirmed, it's locked in — there’s no going back. This reduces the risk of someone sneaking in an invalid transaction or causing conflicts. Imagine playing a game of Monopoly where no one can go back and undo moves after their turn is over. It makes things fairer and prevents shady play.


________________


Section 2 - Articles written by Ben Thompson
Article 1 - AI’s Uneven Arrival
Box’s route to its IPO, ten years ago this month, was a difficult one: the company first released an S-1 in March 2014, and potential investors were aghast at the company’s mounting losses; the company took a down round and, eight months later, released an updated S-1 that created the template for money-losing SaaS businesses to explain themselves going forward:


Our business model focuses on maximizing the lifetime value of a customer relationship. We make significant investments in acquiring new customers and believe that we will be able to achieve a positive return on these investments by retaining customers and expanding the size of our deployments within our customer base over time…


We experience a range of profitability with our customers depending in large part upon what stage of the customer phase they are in. We generally incur higher sales and marketing expenses for new customers and existing customers who are still in an expanding stage…For typical customers who are renewing their Box subscriptions, our associated sales and marketing expenses are significantly less than the revenue we recognize from those customers.


SaaS company cohort analysis
This was the justification for those top-line losses; I wrote in an Update at the time:


That right there is the SaaS business model: you’re not so much selling a product as you are creating annuities with a lifetime value that far exceeds whatever you paid to acquire them. Moreover, if the model is working — and in retrospect, we know it has for that 2010 cohort — then I as an investor absolutely would want Box to spend even more on customer acquisition, which, of course, Box has done. The 2011 cohort is bigger than 2010, the 2012 cohort bigger than 2011, etc. This, though, has meant that the aggregate losses have been very large, which looks bad, but, counterintuitively, is a good thing.


Numerous SaaS businesses would include some version of this cohort chart in their S-1’s, each of them manifestations of what I’ve long considered tech’s sixth giant: Apple, Amazon, Google, Meta, Microsoft, and what I call “Silicon Valley Inc.”, the pipeline of SaaS companies that styled themselves as world-changing startups but which were, in fact, color-by-numbers business model disruptions enabled by cloud computing and a dramatically expanded venture capital ecosystem that increasingly accepted relatively low returns in exchange for massively reduced risk profiles.


This is not, to be clear, an Article about Box, or any one SaaS company in particular; it is, though, an exploration of how an era that opened — at least in terms of IPOs — a decade ago is both doomed in the long run and yet might have more staying power than you expect.


Digital Advertising Differences
John Wanamaker, a department store founder and advertising pioneer, famously said, “Half the money I spend on advertising is wasted; the trouble is I don’t know which half.” That, though, was the late 19th century; the last two decades have seen the rise of digital advertising, the defining characteristic of which is knowledge about whom is being targeted, and whether or not they converted. The specifics of how this works have shifted over time, particularly with the crackdown on cookies and Apple’s App Tracking Transparency initiative, which made digital advertising less deterministic and more probabilistic; the probabilities at play, though, are a lot closer to 100% than they are to a flip-of-a-coin.


What is interesting is that this advertising approach hasn’t always worked for everything, most notably some of the most advertising-centric businesses in the world. Back in 2016 Procter & Gamble announced they were scaling back targeted Facebook ads; from the Wall Street Journal:


Procter & Gamble Co., the biggest advertising spender in the world, will move away from ads on Facebook that target specific consumers, concluding that the practice has limited effectiveness. Facebook Inc. has spent years developing its ability to zero in on consumers based on demographics, shopping habits and life milestones. P&G, the maker of myriad household goods including Tide and Pampers, initially jumped at the opportunity to market directly to subsets of shoppers, from teenage shavers to first-time homeowners.


Marc Pritchard, P&G’s chief marketing officer, said the company has realized it took the strategy too far. “We targeted too much, and we went too narrow,” he said in an interview, “and now we’re looking at: What is the best way to get the most reach but also the right precision?”…On a broader scale, P&G’s shift highlights the limits of such targeting for big brands, one of the cornerstones of Facebook’s ad business. The social network is able to command higher prices for its targeted marketing; the narrower the targeting the more expensive the ad.


P&G is a consumer packaged goods (CPG) company, and what mattered most for CPG companies was shelf space. Consumers would become aware of a brand through advertising, motivated to buy through things like coupons, and the payoff came when they were in the store and chose one of the CPG brands off the shelf; of course CPG companies paid for that shelf space, particularly coveted end-caps that made it more likely consumers saw the brands they were familiar with through advertising. There were returns to scale, as well: manufacturing is a big one; the more advertising you bought the less paid per ad; more importantly, the more shelf space you had the more room you had to expand your product lines, and crowd out competitors.


The advertising component specifically was usually outsourced to ad agencies, for reasons I explained in a 2017 Article:


Few advertisers actually buy ads, at least not directly. Way back in 1841, Volney B. Palmer, the first ad agency, was opened in Philadelphia. In place of having to take out ads with multiple newspapers, an advertiser could deal directly with the ad agency, vastly simplifying the process of taking out ads. The ad agency, meanwhile, could leverage its relationships with all of those newspapers by serving multiple clients:


A drawing of The Pre-Internet Ad Agency Structure
It’s a classic example of how being in the middle can be a really great business opportunity, and the utility of ad agencies only increased as more advertising formats like radio and TV became available. Particularly in the case of TV, advertisers not only needed to place ads, but also needed a lot more help in making ads; ad agencies invested in ad-making expertise because they could scale said expertise across multiple clients.


At the same time, the advertisers were rapidly expanding their geographic footprints, particularly after the Second World War; naturally, ad agencies increased their footprint at the same time, often through M&A. The overarching business opportunity, though, was the same: give advertisers a one-stop shop for all of their advertising needs.


The Internet provided two big challenges to this approach. First, the primary conversion point changed from the cash register to the check-out page; the products that benefited the most were either purely digital (like apps) or — at least in the earlier days of e-commerce — spur-of-the-moment purchases without major time pressure. CPG products didn’t really fall in either bucket.


Second, these types of purchases aligned well with the organizing principle of digital advertising, which is the individual consumer. What Facebook — now Meta — is better at than anyone in the world is understanding consumers not as members of a cohort or demographic group but rather as individuals, and serving them ads that are uniquely interesting to them.


Notice, though, that nothing in the traditional advertiser model was concerned with the individual: brands are created for cohorts or demographic groups, because they need to be manufactured at scale; then, ad agencies would advertise at scale — making money along the way — and the purchase would be consummated in physical stores at some later point in time, constrained (and propelled by) limited shelf space. Thus P&G’s pullback — and thus the opportunity for an entirely new wave of companies that were built around digital advertising and its deep personalization from the get-go.


This bifurcation manifested itself most starkly in the summer of 2020, when large advertisers boycotted Facebook over the company’s refusal to censor then-President Trump; Facebook was barely affected. I wrote in Apple and Facebook:


This is a very different picture from Facebook, where as of Q1 2019 the top 100 advertisers made up less than 20% of the company’s ad revenue; most of the $69.7 billion the company brought in last year came from its long tail of 8 million advertisers…


This explains why the news about large CPG companies boycotting Facebook is, from a financial perspective, simply not a big deal. Unilever’s $11.8 million in U.S. ad spend, to take one example, is replaced with the same automated efficiency that Facebook’s timeline ensures you never run out of content. Moreover, while Facebook loses some top-line revenue — in an auction-based system, less demand corresponds to lower prices — the companies that are the most likely to take advantage of those lower prices are those that would not exist without Facebook, like the direct-to-consumer companies trying to steal customers from massive conglomerates like Unilever.


In this way Facebook has a degree of anti-fragility that even Google lacks: so much of its business comes from the long tail of Internet-native companies that are built around Facebook from first principles, that any disruption to traditional advertisers — like the coronavirus crisis or the current boycotts — actually serves to strengthen the Facebook ecosystem at the expense of the TV-centric ecosystem of which these CPG companies are a part.


It has been nine years since that P&G pullback I referenced above, and one of the big changes that P&G has made in that timeframe is to take most of their ad-buying in-house. This was in the long run inevitable, as the Internet ate everything, including traditional TV viewing, and as the rise of Aggregation platforms meant that the number of places you needed to actually buy an ad to reach everyone decreased even as potential reach increased. Those platforms also got better: programmatic platforms achieve P&G’s goal of mass reach in a way that actually increased efficiency instead of over-spending to over-target; programmatic advertising also covers more platforms now, including TV.


o3 Ammunition
Late last month OpenAI announced its o3 model, validating its initial o1 release and the returns that come from test-time scaling; I explained in an Update when o1 was released:


There has been a lot of talk about the importance of scale in terms of LLM performance; for auto-regressive LLMs that has meant training scale. The more parameters you have, the larger the infrastructure you need, but the payoff is greater accuracy because the model is incorporating that much more information. That certainly still applies to o1, as the chart on the left indicates.


o1 scales with both training and inference compute
It’s the chart on the right that is the bigger deal: o1 gets more accurate the more time it spends on compute at inference time. This makes sense intuitively given what I laid out above: the more time spent on compute the more time o1 can spend spinning up multiple chains-of-thought, checking its answers, and iterating through different approaches and solutions.


It’s also a big departure from how we have thought about LLMs to date: one of the “benefits” of auto-regressive LLMs is that you’re only generating one answer in a serial manner. Yes, you can get that answer faster with beefier hardware, but that is another way of saying that the pay-off from more inference compute is getting the answer faster; the accuracy of the answer is a function of the underlying model, not the amount of compute brought to bear. Another way to think about it is that the more important question for inference is how much memory is available; the more memory there is, the larger the model, and therefore, the greater amount of accuracy.


In this o1 represents a new inference paradigm: yes, you need memory to load the model, but given the same model, answer quality does improve with more compute. The way that I am thinking about it is that more compute is kind of like having more branch predictors, which mean more registers, which require more cache, etc.; this isn’t a perfect analogy, but it is interesting to think about inference compute as being a sort of dynamic memory architecture for LLMs that lets them explore latent space for the best answer.


o3 significantly outperforms o1, and the extent of that outperformance is dictated by how much computing is allocated to the problem at hand. One of the most stark examples was o3‘s performance on the ARC prize, a visual puzzle test that is designed to be easy for humans but hard for LLMs:


OpenAI’s new o3 system – trained on the ARC-AGI-1 Public Training set – has scored a breakthrough 75.7% on the Semi-Private Evaluation set at our stated public leaderboard $10k compute limit. A high-compute (172x) o3 configuration scored 87.5%.


o3 test results on ARC
This is a surprising and important step-function increase in AI capabilities, showing novel task adaptation ability never seen before in the GPT-family models. For context, ARC-AGI-1 took 4 years to go from 0% with GPT-3 in 2020 to 5% in 2024 with GPT-4o. All intuition about AI capabilities will need to get updated for o3…


Despite the significant cost per task, these numbers aren’t just the result of applying brute force compute to the benchmark. OpenAI’s new o3 model represents a significant leap forward in AI’s ability to adapt to novel tasks. This is not merely incremental improvement, but a genuine breakthrough, marking a qualitative shift in AI capabilities compared to the prior limitations of LLMs. o3 is a system capable of adapting to tasks it has never encountered before, arguably approaching human-level performance in the ARC-AGI domain.


Of course, such generality comes at a steep cost, and wouldn’t quite be economical yet: you could pay a human to solve ARC-AGI tasks for roughly $5 per task (we know, we did that), while consuming mere cents in energy. Meanwhile o3 requires $17-20 per task in the low-compute mode. But cost-performance will likely improve quite dramatically over the next few months and years, so you should plan for these capabilities to become competitive with human work within a fairly short timeline.


I don’t believe that o3 and inference-time scaling will displace traditional LLMs, which will remain both faster and cheaper; indeed, they will likely make traditional LLMs better through their ability to generate synthetic data for further scaling of pre-training. There remains a large product overhang for traditional LLMS — the technology is far more capable than the products that have been developed to date — but even the current dominant product, chatbots, are better experienced with a traditional LLM.


That very use case, however, gets at traditional LLM limitations: because they lack the ability to think and decide and verify they are best thought of as a tool for humans to leverage. Indeed, while conventional wisdom about these models is that it allows anyone to generate good enough writing and research, the biggest returns come to those with the most expertise and agency, who are able to use their own knowledge and judgment to reap efficiency gains while managing hallucinations and mistakes.


What o3 and inference-time scaling point to is something different: AI’s that can actually be given tasks and trusted to complete them. This, by extension, looks a lot more like an independent worker than an assistant — ammunition, rather than a rifle sight. That may seem an odd analogy, but it comes from a talk Keith Rabois gave at Stanford:




So I like this idea of barrels and ammunition. Most companies, once they get into hiring mode…just hire a lot of people, you expect that when you add more people your horsepower or your velocity of shipping things is going to increase. Turns out it doesn’t work that way. When you hire more engineers you don’t get that much more done. You actually sometimes get less done. You hire more designers, you definitely don’t get more done, you get less done in a day.


The reason why is because most great people actually are ammunition. But what you need in your company are barrels. And you can only shoot through the number of unique barrels that you have. That’s how the velocity of your company improves is adding barrels. Then you stock them with ammunition, then you can do a lot. You go from one barrel company, which is mostly how you start, to a two barrel company, suddenly you get twice as many things done in a day, per week, per quarter. If you go to three barrels, great. If you go to four barrels, awesome. Barrels are very difficult to find. But when you have them, give them lots of equity. Promote them, take them to dinner every week, because they are virtually irreplaceable. They are also very culturally specific. So a barrel at one company may not be a barrel at another company because one of the ways, the definition of a barrel is, they can take an idea from conception and take it all the way to shipping and bring people with them. And that’s a very cultural skill set.


The promise of AI generally, and inference-time scaling models in particular, is that they can be ammunition; in this context, the costs — even marginal ones — will in the long run be immaterial compared to the costs of people, particularly once you factor in non-salary costs like coordination and motivation.


The Uneven AI Arrival
There is a long way to go to realize this vision technically, although the arrival of first o1 and then o3 signal that the future is arriving more quickly than most people realize. OpenAI CEO Sam Altman wrote on his blog:


We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents “join the workforce” and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.


I grant the technical optimism; my definition of AGI is that it can be ammunition, i.e. it can be given a task and trusted to complete it at a good-enough rate (my definition of Artificial Super Intelligence (ASI) is the ability to come up with the tasks in the first place). The reason for the extended digression on advertising, however, is to explain why I’m skeptical about AI “materially chang[ing] the output of companies”, at least in 2025.


In this analogy CPG companies stand in for the corporate world generally. What will become clear once AI ammunition becomes available is just how unsuited most companies are for high precision agents, just as P&G was unsuited for highly-targeted advertising. No matter how well-documented a company’s processes might be, it will become clear that there are massive gaps that were filled through experience and tacit knowledge by the human ammunition.


SaaS companies, meanwhile, are the ad agencies. The ad agencies had value by providing a means for advertisers to scale to all sorts of media across geographies; SaaS companies have value by giving human ammunition software to do their job. Ad agencies, meanwhile, made money by charging a commission on the advertising they bought; SaaS companies make money by charging a per-seat licensing fee. Look again at that S-1 excerpt I opened with:


Our business model focuses on maximizing the lifetime value of a customer relationship. We make significant investments in acquiring new customers and believe that we will be able to achieve a positive return on these investments by retaining customers and expanding the size of our deployments within our customer base over time…


The positive return on investment comes from retaining and increasing seat licenses; those seats, however, are proxies for actually getting work done, just as advertising was just a proxy for actually selling something. Part of what made direct response digital advertising fundamentally different is that it was tied to actually making a sale, as opposed to lifting brand awareness, which is a proxy for the ultimate goal of increasing revenue. To that end, AI — particularly AI’s like o3 that scale with compute — will be priced according to the value of the task they complete; the amount that companies will pay for inference time compute will be a function of how much the task is worth. This is analogous to digital ads that are priced by conversion, not CPM.


The companies that actually leveraged that capability, however, were not, at least for a good long while, the companies that dominated the old advertising paradigm. Facebook became a juggernaut by creating its own customer base, not by being the advertising platform of choice for companies like P&G; meanwhile, TV and the economy built on it stayed relevant far longer than anyone expected. And, by the time TV truly collapsed, both the old guard and digital advertising had evolved to the point that they could work together.


If something similar plays out with AI agents, then the most important AI customers will primarily be new companies, and probably a lot of them will be long tail type entities that take the barrel and ammunition analogy to its logical extreme. Traditional companies, meanwhile, will struggle to incorporate AI (outside of whole-scale job replacement a la the mainframe); the true AI takeover of enterprises that retain real world differentiation will likely take years.


None of this is to diminish what is coming with AI; rather, as the saying goes, the future may arrive but be unevenly distributed, and, contrary to what you might think, the larger and more successful a company is the less they may benefit in the short term. Everything that makes a company work today is about harnessing people — and the entire SaaS ecosystem is predicated on monetizing this reality; the entities that will truly leverage AI, however, will not be the ones that replace them, but start without them.


________________


Article 2 - Boomer Apple


I was born in 1980, which technically makes me a part of Generation X; there is at least one data point, though, that makes me a millennial. In 2021 Fast Company conducted a survey about what constituted middle age; millennials defined it as 35 to 50, while Generation X said 45 to 55 (Baby Boomers said 45 to 60).


For my part, I wrote that Apple was in its middle age in 2018, when the company was 42 years old, a solidly millennial definition. My argument then was that Apple was increasingly — and rightly — behaving like an incumbent in a market that was no longer growing. That meant that future iPhone growth would come from (1) more expensive iPhones, (2) selling more devices to existing iPhone users (AirPods, Watches, etc.), and (3) accelerating the revenue it derived from services for iPhone users.


That is exactly what the company did over the ensuing few years, but 2022 brought a bit of a surprise: Apple, in the face of the worst inflation in a generation, declined to raise the price of the iPhone, which in real terms meant an iPhone Pro, nominally priced at $999, was $116 cheaper than it had been two years prior.


I thought this was a big deal at the time; I wrote in The Services iPhone:


This doesn’t make much sense for the product company Apple has always been thought to be, and doesn’t fully align with the approach I laid out in Apple’s Middle Age. It does, though, make all kinds of sense for a services company, which is focused first-and-foremost on increasing its install base. Indeed, this is the missing piece from that Update I wrote about Apple’s changing metrics. To measure its business based on users, not products, was to measure like a services company; to lower the prices of the products that lead to services revenue is to price like one.


Here’s another aspect of getting old: it’s hard to let go of the preconceptions of your youth. In yesterday’s Update I wrote that I believed that Apple would surely raise prices this year; that $999 iPhone Pro is now $177 cheaper than in 2020 in real terms, and given the fact that Apple was increasing the bill of materials on the lower end phones in particular (bumping them to 8GB RAM, and onto the latest TSMC process), surely they wouldn’t accept the hit on margins on top of the loss in value of their longstanding iPhone pricing.


         2020        2021        2022        2023        2024
2 year old iPhone        $499        $477        $441        $422        $411
1 year old iPhone        $599        $572        $530        $507        $493
New iPhone        $799        $763        $707        $676        $657
iPhone Pro        $999        $954        $883        $846        $822
iPhone Pro Max        $1,099        $1,050        $972        $1,015        $904
In fact, though, I had it right in 2022: Apple held the line on prices once again; I should have realized the company — like myself! — really is in a different stage.


The iPhone Event
The lack of a price increase for the iPhone 16 Pro made more sense when I watched Apple’s presentation; I found the updates over the iPhone 15 Pro to be pretty underwhelming. The A18 Pro chip is on TSMC’s newest 3nm process, there is a new Camera Control button, and the screen is a bit bigger with bezels that are a bit smaller; that’s really about it from a hardware perspective, although as always, Apple continues to push the envelope with computational photography. And, frankly, that’s fine: last year’s iPhone Pro 15, the first with titanium and USB-C, was for me the iPhone I had been waiting for (and most customers don’t upgrade every year, so these and other previous updates will be new features for them).


What I find much more compelling — and arguably the best deal in iPhone history — is the $799 iPhone 16 (non-Pro). The A18 chip appears to be a binned version of the A18 Pro (there is one less GPU and smaller caches), while the aforementioned bump to 8GB of RAM — necessary to run Apple Intelligence — matches the iPhone 16 Pro. There is one fewer camera, but the two-camera system that remains has been reconfigured to a much more aesthetically pleasing pill shape that has the added bonus of making it possible to record spatial video when held horizontally. The screen isn’t quite as good, and the bezels are a bit larger, but the colors are more fun. It’s a great phone, and the closest the regular iPhone has been to the Pro since the line separated in 2017.


It’s also the more important phone when it comes to Apple’s long-term addressable market. The non-pro iPhones are the ones that stay on sale for years (the iPhone 14 just received its expected price drop to $599); one potential consideration for Apple in terms of price is that it wants to move the 8GB RAM iPhone 16 down the line sooner rather than later; a price raise, if it meant keeping a 6GB RAM iPhone for sale one year longer, could be bad for Apple Intelligence.


Apple Intelligence, meanwhile, is the great hope when it comes to driving new iPhone sales: Apple shareholders are hoping for an AI-driven “supercycle”, when consumers, eager for Apple Intelligence features, update their iPhones to one of the latest models with sufficient RAM to run Apple’s new tentpole offering.


Apple’s Crossing Lines
Notice, though, that this hope itself speaks to how Apple is at a different stage in life: the big hardware changes this year are at the low end; one of the takeaways from AI is that we are well and truly into the age of software-driven differentiation. This is hardly a surprise; I wrote in 2016’s Everything as a Service:


Apple has arguably perfected the manufacturing model: most of the company’s corporate employees are employed in California in the design and marketing of iconic devices that are created in Chinese factories built and run to Apple’s exacting standards (including a substantial number of employees on site), and then transported all over the world to consumers eager for best-in-class smartphones, tablets, computers, and smartwatches.


What makes this model so effective — and so profitable — is that Apple has differentiated its otherwise commoditizable hardware with software. Software is a completely new type of good in that it is both infinitely differentiable yet infinitely copyable; this means that any piece of software is both completely unique yet has unlimited supply, leading to a theoretical price of $0. However, by combining the differentiable qualities of software with hardware that requires real assets and commodities to manufacture, Apple is able to charge an incredible premium for its products.


The results speak for themselves: this past “down” quarter saw Apple rake in $50.6 billion in revenue and $10.5 billion in profit. Over the last nine years the iPhone alone has generated $600 billion in revenue and nearly $250 billion in gross profit. It is probably the most valuable — the “best”, at least from a business perspective — manufactured product of all time.


In the eight years since then the iPhone has driven another $1.4 trillion in revenue and something around $625 billion in profit;  it is still tops in the company for both. It is software, though, specifically services revenue that doesn’t depend on how good the underlying hardware is, that is 2nd place in terms of revenue:


Apple's revenue by product line 
The comparison is even more striking when you look at profit (again, with the assumption that iPhones have a 45% gross profit margin):


Apple's iPhone vs Services profit
Jason Snell already noted the impending convergence of the overall product and services profit lines at Six Colors:


But what about the bottom line? While Apple’s Services gross margin was 74% last quarter, products was only a measly 35%. (I’m kidding—35% margin on hardware is actually a really great number. It just can’t compare to Services, because hardware has some fundamental costs that services just don’t.)


Let’s look at total profits:


Apple's total profit dollars from products and services
Last quarter, Apple made about $22 billion in profit from products and $18 billion from Services. It’s the closest those two lines have ever come to each other.


This is what was buzzing in the back of my head as I was going over all the numbers on Thursday. We’re not quite there yet, but it’s hard to imagine that there won’t be a quarter in the next year or so in which Apple reports more total profit on Services than on products.


When that happens, is Apple still a products company? Or has it crossed some invisible line?


Snell concludes his piece by imploring Apple to “remember where you came from”; hardware is what makes the whole thing work. I’m sympathetic to Snell’s case, because Apple the integrated hardware company is both an entity I admire and one that — as evidenced by my mistaken prediction yesterday — still looms large in my mind. Moreover, you can can (and should) make the case that Services revenue and profit is just an accounting distinction for what is just more hardware revenue and profit, because it is the latter that unlocks the former.


That, though, is why I broke out the iPhone specifically: I think the invisible line Snell talks about has already been crossed. Yes, next quarter’s iPhone numbers will jump back up thanks to seasonality, but this is now three straight years of Apple either favoring its more reliably growing Services business (by increasing the iPhone’s addressable market by lowering real prices) or admitting that it doesn’t have the pricing power that drove up product revenue in their middle age.


Boomer Apple
This is not, to be clear, an “Apple is Doomed” post; Apple hardware is still very good, and in lots of small ways that go beyond new buttons. I’ve been exploring the Android market over the past few weeks and there is a level of “it just works” that still differentiates the iPhone, particularly in terms of overall system integration (relative to the Pixel, which has a poor modem and problematic battery life) and worldwide reliability (relative to Samsung devices that are endlessly segmented in weird ways across markets, a hangup for me in particular).


Moreover, it’s hardly a condemnation for hardware to become “good enough”, and to decrease in price over time; that has been the path of basically all consumer electronics.


Computers and consumer electronics decline in price over time
It’s impressive that Apple was innovative enough to resist gravity for as long as it did.


And, of course, there is the lock-in endemic to software: iMessage only works on iPhones,  there are all of the apps you have already purchased, and, the muscle memory of years in a particular ecosystem. There are Watches and AirPods that only work or work best with iPhones, and the deep integration with Macs. Apple’s chips remain best-of-breed, and the company’s investment in privacy may pay off in the AI era as people trust Apple to leverage their personal data on device and in their new private cloud.


That, though, is the rub: Craig Federighi, Apple’s software chief, usually doesn’t appear at the iPhone event; his domain is the Worldwide Developers Conference in June, and yet here he was in front of the camera for ten minutes.


Apple's software chief was featured for 10 minutes of the hardware keynote
Software, specifically AI, is what will drive differentiation going forward, and even in the best case scenario, where Apple’s AI efforts are good enough to keep people from switching to Google, the economics of software development push towards broad availability on every iPhone, not special features for people willing to pay a bit more. It’s as if the iPhone, which started out as one model for everyone before bifurcating into the Pro and regular (and SE) lines, is coming full circle to standardization; the difference, though, is its value is harvested through R&D intensive services that need to run everywhere, instead of unit profits driven by hardware differentiation.


So what stage of life is this, where you are banking on your earlier investments for your moat, and having no choice but to strive for good enough on the hot new trends that don’t quite fit your model? Maybe it’s the age where you’re worried about things like irregular heart beats, sleep apnea, or hearing loss. I’m not meaning to make fun of the health features that are an ever larger focus of these events; these are incredible applications of technology that Apple is right to brag about. Indeed, these features make me want to wear an Apple Watch or use AirPods.


But I’m old, and so enamored of the companies of my youth that I ignored my own (correct!) analysis of Apple’s shift in a desire to believe that this was still a product company that could wow me and charge me like it did in 2020. This is a services company now; the hardware is necessary, but insufficient for long-term growth. So it goes.


________________


Article 3 - Elon Dreams and Bitter Lessons
In the days after SpaceX’s awe-inspiring Starship launch-and-catch — watch the first eight minutes of this video if you haven’t yet — there was another older video floating around on X, this time of Richard Bowles, a former executive at Arianespace, the European rocket company. The event was the Singapore Satellite Industry Forum, and the year was 2013:




This morning, SpaceX came along and said, “We foresee a launch costing $7 million”. Well, ok, let’s ignore the 7, let’s say $15 million…at $15 million every operator would change their gameplane completely. Every supplier would change their gameplan completely. We wouldn’t be building satellites exactly as we are today, so a lot of these questions I think it might be interesting to go on that and say, “Where do you see your companies if you’re going to compete with a $15 million launch program.” So Richard, where do you see your company competing with a $15 million launch?”…


RB: SpaceX is an interesting phenomenon. We saw it, and you just mentioned it, I thought it was $5 million or $7 million…


Why don’t you take Arianespace instead of SpaceX first. Where would you compete with a $15 million launch?


RB: I’ve got to talk about what I’m competing with, because that then predicates exactly how we will compete when we analyze what we are competing with. Obviously we like to analyze the competition.


So today, SpaceX hasn’t launched into the geosynchronous orbit yet, they’re doing very well, their progress is going forward amazingly well, but I’m discovering in the market is that SpaceX primarily seems to be selling a dream, which is good, we should all dream, but I think a $5 million launch, or a $15 million launch, is a bit of a dream. Personally I think reusability is a dream. Recently I was at a session where I was told that there was no recovery plan because they’re not going to have any failures, so I think that’s a part of the dream.


So at the moment, I feel that we’re looking, and you’re presenting to me, how am I going to respond to a dream? My answer to respond to a dream is that first of all, you don’t wake people up, they have to wake up on their own, and then once the market has woken up to the dream and the reality, then we’ll compete with that.


But they are looking at a price which is about half yours today.


RB: It’s a dream.


Alright. Suppose that you wake up and they’re there, what would you Arianespace do.


RB: We would have to react to it. They’re not supermen, so whatever they can do we can do. We would then have to follow. But today, at the moment…it is a theoretical question at this moment in time.


I personally don’t believe it’s going to be theoretical for that much longer. They’ve done everything almost they said they would do. That’s true.


The moderator ended up winning the day; in 2020 Elon Musk said on a podcast that the “best case” for Falcon 9 launches was indeed $15 million (i.e. most cost more, but that price point had been achieved). Of course customers pay a lot more: SpaceX charges a retail price of $67 million per launch, in part because it has no competition; Arianespace retired the Ariane 5 rocket, which had a retail launch price of $178 million, in 2023. Ariane 6 had its first launch this year, but it’s not price competitive, in part because it’s not reusable. From Politico:


The idea of copying SpaceX and making Ariane partly reusable was considered and rejected. That decision haunts France’s Economy Minister Bruno Le Maire. “In 2014 there was a fork in the road, and we didn’t take the right path,” Le Maire said in 2020.


But just because it works for Elon, doesn’t make it good for Europe. Once it’s up and running, Ariane 6 should have nine launches a year — of which around four will be for institutional missions, like government reconnaissance satellites and earth observation systems. The rest will be targeted at commercial clients.


Compare that to SpaceX. Fed by a steady stream of Pentagon and industry contracts, in addition to missions for its own Starlink satellite constellation, Musk’s company carried out a record 96 launches in 2023.


“It wasn’t that we just said reusability is bullshit,” said [former head the European Space Agency Jan] Wörner of the early talks around Ariane 6 in the mid-2010s, and the consideration of building reusable stages rather than burning through fresh components each mission. “If you have 10 flights per year and you are only building one new launcher per year then from an industrial point of view that’s not going to work.”


Wörner’s statement is like Bowles in the way in which it sees the world as static; Bowles couldn’t see ahead to a world where SpaceX actually figured out how to reuse rockets by landing them on drone ships, much less the version 2 example of catching a much larger rocket that we saw this weekend. Wörner, meanwhile, can’t see backwards: the reason why SpaceX has so much more volume, both from external customers and from itself (Starlink), is because it is cheap. Cheapness creates scale, which makes things even cheaper, and the ultimate output is entirely new markets.


The SpaceX Dream
Of course Bowles was right in another way: SpaceX is a dream. It’s a dream of going to Mars, and beyond, of extending humanity’s reach beyond our home planet; Arianespace is just a business. That, though, has been their undoing. A business carefully evaluates options, and doesn’t necessarily choose the highest upside one, but rather the one with the largest expected value, a calculation that incorporates the likelihood of success — and even then most find it prudent to hedge, or build in option value.


A dreamer, though, starts with success, and works backwards. In this case, Musk explained the motivation for driving down launch costs on X:


Why Musk is focused on launch costs
First off, this made it imperative that SpaceX find a way to launch a massively larger rocket that is fully recoverable, and doesn’t include the weight and logistics costs of the previous approach (this weekend SpaceX caught the Super Heavy booster; the next step is catching the Starship spacecraft that sits above it). Once SpaceX can launch massively larger rockets cheaply, though, it can start to do other things, like dramatically expand Starlink capability.






Starlink won’t be the only beneficiary; the Singapore moderator had it right back in 2013: everyone will change their gameplan completely, which will mean more business for SpaceX, which will only make things cheaper, which will mean even more business. Indeed, there is a window to rocketports that don’t have anything to do with Mars, but simply facilitate drastically faster transportation here on planet earth. The transformative possibilities of scale — and the dramatic decrease in price that follows — are both real and hard to imagine.


Tesla’s Robotaxi Presentation
The Starship triumph wasn’t the only Musk-related story of the week: last Thursday Tesla held its We, Robot event where it promised to unveil its Robotaxi, and observers were considerably less impressed. From Bloomberg:


Elon Musk unveiled Tesla Inc.’s highly anticipated self-driving taxi at a flashy event that was light on specifics, sending its stock sliding as investors questioned how the carmaker will achieve its ambitious goals. The chief executive officer showed off prototypes of a slick two-door sedan called the Cybercab late Thursday, along with a van concept and an updated version of Tesla’s humanoid robot. The robotaxi — which has no steering wheel or pedals — could cost less than $30,000 and “probably” will go into production in 2026, Musk said.


The product launch, held on a movie studio lot near Los Angeles, didn’t address how Tesla will make the leap from selling advanced driver-assistance features to fully autonomous vehicles. Musk’s presentation lacked technical details and glossed over topics including regulation or whether the company will own and operate its own fleet of Cybercabs. As Jefferies analysts put it, Tesla’s robotaxi appears “toothless.”


The underwhelming event sent Tesla’s shares tumbling as much as 10% Friday in New York, the biggest intraday decline in more than two months. They were down 7.6% at 12:29 p.m., wiping out $58 billion in market value. The stock had soared almost 70% since mid-April, largely in anticipation of the event. Uber Technologies Inc. and Lyft Inc., competing ride-hailing companies whose investors had been nervously awaiting the Cybercab’s debut, each surged as much as 11% Friday. Uber’s stock hit an all-time high.


Tesla has a track record of blowing past timelines Musk has offered for all manner of future products, and has had a particularly difficult time following through on his self-driving forecasts. The CEO told investors in 2019 that Tesla would have more than 1 million robotaxis on the road by the following year. The company hasn’t deployed a single autonomous vehicle in the years since.


First off, the shockingly short presentation — 22:44 from start to “Let’s get the party started” — was indeed devoid of any details about the Robotaxi business case. Secondly, all of the criticisms of Musk’s mistaken predictions about self-driving are absolutely true. Moreover, the fact of the matter is that Tesla is now far behind the current state-of-the-art, Waymo, which is in operation in four U.S. cities and about to start up in two more. Waymo has achieved Level 4 automation, while Tesla’s are stuck at Level 2. To review the levels of automation:


Level 0: Limited features that provide warnings and momentary assistance (i.e. automatic emergency braking)
Level 1: Steering or brake/acceleration automation (i.e. cruise control or lane centering)
Level 2: Steering and brake/acceleration control, which must be constantly supervised (i.e. hands-on-wheel)
Level 3: Self-driving that only operates under pre-defined conditions, and in which the driver must take control immediately when requested
Level 4: Self-driving that only operates under pre-defined conditions, under which the driver is not expected to take control
Level 5: Self-driving under all conditions, with no expectation of driver control
Waymo has two big advantages relative to Tesla: first, its cars have a dramatically more expansive sensor suite, including camera, radar, and LiDAR; the latter is the most accurate way to measure depth, which is particularly tricky for cameras and fairly imprecise for radar. Second, any Waymo car can be taken over by a remote driver any time it encounters a problem. This doesn’t happen often — once every 17,311 miles in sunny California last year — but it is comforting to know that there is a fallback.


The challenge is that both of these advantages cost money: LiDAR is the biggest reason why the Generation 5 Waymo’s on the streets of San Francisco cost a reported $200,000; Generation 6 has fewer sensors and should be considerably cheaper, and prices will come down as Waymo scales, but this is still a barrier. Humans in data centers, meanwhile, sitting poised to take over a car that encounters trouble, are not just a cost center but also a limit on scalability. Then again, higher cost structures are its own limitation on scalability; Waymos are awesome but they will need to get an order of magnitude cheaper to change the world.


The Autonomy Dream
What was notable about Musk’s Tesla presentation is what it actually did include. Start with that last point; Musk’s focus was on that changing the world bit:




You see a lot of sci-fi movies where the future is dark and dismal. It’s not a future you want to be in. I love Bladerunner, but I don’t know if we want that future. I think we want that duster he’s wearing, but not the bleak apocalypse. We want to have a fun, exciting future that if you could look in a crystal ball and see the future, you’d be like “Yes, I wish that I could be there now”. That’s what we want.


Musk proceeded to talk about having a lounge on wheels that gave you your time back and was safer to boot, and which didn’t need ugly parking lots; the keynote slides added parks to LAX and Sofi and Dodger Stadiums:




One of the things that is really interesting is how will this affect the cities that we live in. When you drive around a city, or the car drive you around the city, you see that there’s a lot of parking lots. There’s parking lots everywhere. There are parking garages. So what would happen if you have an autonomous world is that you can now turn parking lots into parks…there’s a lot of opportunity to create greenspace in the cities that we live in.


This is certainly an attractive vision; it’s also far beyond the world of Uber and Lyft or even Waymo, which are focused on solving the world as it actually exists today. That means dealing with human drivers, which means there will be parking lots for a long time to come. Musk’s vision is a dream.


What, though, would that dream require, if it were to come true? Musk said it himself: full autonomy provided by a fleet of low cost vehicles that make it silly — or prohibitively expensive, thanks to sky-rocketing insurance — for anyone to drive themselves. That isn’t Level 4, like Waymo, it’s Level 5, and, just as importantly, it’s cheap, because cheap drives scale and scale drives change.


Tesla’s strategy for “cheap” is well-known: the company eschews LiDAR, and removed radar from new models a few years ago, claiming that it would accomplish its goals using cameras alone.  Setting aside the viability of this claim, the connection to the the dream is clear: a cameras-only approach enables the low cost vehicles integral to Musk’s dream. Yes, Waymo equipment costs will come down with scale, but Waymo’s current approach is both safer in the present and also more limited in bringing about the future.


What many folks seemed to miss in Musk’s presentation was his explanation as to how Tesla — and only Tesla — might get there.


The Bitter Lesson
Rich Sutton wrote one of the most important and provocative articles about AI in 2019; it’s called The Bitter Lesson:


The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin. The ultimate reason for this is Moore’s law, or rather its generalization of continued exponentially falling cost per unit of computation. Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available. Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation. These two need not run counter to each other, but in practice they tend to. Time spent on one is time not spent on the other. There are psychological commitments to investment in one approach or the other. And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation. There were many examples of AI researchers’ belated learning of this bitter lesson, and it is instructive to review some of the most prominent.


The examples Sutton goes over includes chess, where search beat deterministic programming, and Go, where unsupervised learning did the same. In both cases bringing massive amounts of compute to bear was both simpler and more effective than humans trying to encode their own shortcuts and heuristics. The same thing happened with speech recognition and computer vision: deep learning massively outperforms any sort of human-guided algorithms. Sutton notes towards the end:


One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.


It’s a brilliant observation, to which I might humbly add one additional component: while the Bitter Lesson is predicated on there being an ever-increasing amount of compute, which reliably solves once-intractable problems, one of the lessons of LLMs is that you also need an ever-increasing amount of data. Existing models are already trained on all of the data AI labs can get their hands on, including most of the Internet, YouTube transcripts, scanned books, etc.; there is much talk about creating synthetic data, both from humans and from other LLMs, to ensure that scaling laws continue. The alternative is that we hit the so-called “data wall”.


LLMs, meanwhile, are commonly thought about in terms of language — it is in the name, after all — but what they actually predict are tokens, and tokens can be anything, including driving data. Timothy Lee explained some of Waymo’s research in this area at Understanding AI:


Any self-driving system needs an ability to predict the actions of other vehicles. For example, consider this driving scene I borrowed from a Waymo research paper:


Waymo research paper scene
Vehicle A wants to turn left, but it needs to do it without running into cars B or D. There are a number of plausible ways for this scene to unfold. Maybe B will slow down and let A turn. Maybe B will proceed, D will slow down, and A will squeeze in between them. Maybe A will wait for both vehicles to pass before making the turn. A’s actions depend on what B and D do, and C’s actions, in turn, depend on what A does.


If you are driving any of these four vehicles, you need to be able to predict where the other vehicles are likely to be one, two, and three seconds from now. Doing this is the job of the prediction module of a self-driving stack. Its goal is to output a series of predictions that look like this:


Waymo research paper visualization
Researchers at Waymo and elsewhere struggled to model interactions like this in a realistic way. It’s not just that each individual vehicle is affected by a complex set of factors that are difficult to translate into computer code. Each vehicle’s actions depend on the actions of other vehicles. So as the number of cars increases, the computational complexity of the problem grows exponentially.


But then Waymo discovered that transformer-based networks were a good way to solve this kind of problem.


“In driving scenarios, road users may be likened to participants in a constant dialogue, continuously exchanging a dynamic series of actions and reactions mirroring the fluidity of communication,” Waymo researchers wrote in a 2023 research paper.


Just as a language model outputs a series of tokens representing text, Waymo’s vehicle prediction model outputs a series of tokens representing vehicle trajectories—things like “maintain speed and direction,” “turn 5 degrees left,” or “slow down by 3 mph”.


Rather than trying to explicitly formulate a series of rules for vehicles to follow (like “stay in your lane” and “don’t hit other vehicles”), Waymo trained the model like an LLM. The model learned the rules of driving by trying to predict the trajectories of human-driven vehicles on real roads.


This data-driven approach allowed the model to learn subtleties of vehicle interactions that are not described in any driver manual and would be hard to capture with explicit computer code.


This is not yet a panacea. Lee notes later in his article:


One big problem Sinavski noted is that Wayve hasn’t found a vision-language model that’s “really good at spatial reasoning.” If you’re a long-time reader of Understanding AI, you might remember when I asked leading LLMs to tell the time from an analog clock or solve a maze. ChatGPT, Claude, and Gemini all failed because today’s foundation models are not good at thinking geometrically.


This seems like it would be a big downside for a model that’s supposed to drive a car. And I suspect it’s why Waymo’s perception system isn’t just one big network. Waymo still uses traditional computer code to divide the driving scene up into discrete objects and compute a numerical bounding box for each one. This kind of pre-processing gives the prediction network a head start as it reasons about what will happen next.


Another concern is that the opaque internals of LLMs make them difficult to debug. If a self-driving system makes a mistake, engineers want to be able to look under the hood and figure out what happened. That’s much easier to do in a system like Waymo’s, where some of the basic data structures (like the list of scene elements and their bounding boxes) were designed by human engineers.


But the broader point here is that self-driving companies do not face a binary choice between hand-crafted code or one big end-to-end network. The optimal self-driving architecture is likely to be a mix of different approaches. Companies will need to learn the best division of labor from trial and error.


That sounds right, but for one thing: The Bitter Lesson. To go back to Sutton:


This is a big lesson. As a field, we still have not thoroughly learned it, as we are continuing to make the same kind of mistakes. To see this, and to effectively resist it, we have to understand the appeal of these mistakes. We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.


If The Bitter Lesson ends up applying to true Level 5 autonomy, then Waymo is already signed up for school. A “mix of different approaches” clearly works better now, and may for the next few years, but does it get them to Level 5? And what of the data, to the extent it is essential to the The Sweet Outcome of self-taught AI? This was the part of the Tesla presentation I referenced above:




One of the reasons why the computer can be so much better than a person is that we have millions of cars that are training on driving. It’s like living millions of lives simultaneously and seeing very unusal situations that a person in their entire lifetime would not see, hopefully. With that amount of training data, it’s obviously going to be much better than what a human could be, because you can’t live a million lives. It can also see in all directions simultaneously, and it doesn’t get tired or text or any of those things, so it will naturally be 10x, 20x, 30x safer than a human for all those reasons.


I want to emphasize that the solution that we have is AI and vision. There’s no expensive equipment needed. The Model 3 and Model Y and S and X that we make today will be capable of full autonomy unsupervised. And that means that our costs of producing the vehicle is low.


Again, Musk has been over-promising and under-delivering in terms of self-driving for existing Tesla owners for years now, so the jury is very much out on whether current cars get full unsupervised autonomy. But that doesn’t change the fact that those cars do have cameras, and those cameras are capturing data and doing fine-tuning right now, at a scale that Waymo has no way of matching. This is what I think Andrej Karpathy, the former Tesla Autopilot head, was referring to in his recent appearance on the No Priors podcast:




I think people think that Waymo is ahead of Tesla, I think personally Tesla is ahead of Waymo, and I know it doesn’t look like that, but I’m still very bullish on Tesla and it’s self-driving program. I think that Tesla has a software problem, and I think Waymo has a hardware problem, is the way I put it, and I think software problems are much easier. Tesla has deployment of all these cars on earth at scale, and I think Waymo needs to get there. The moment Tesla gets to the point where they can actually deploy and it actually works I think is going to be really incredible…


I’m not sure that people are appreciating that Tesla actually does use a lot of expensive sensors, they just do it at training time. So there a bunch of cars that drive around with LiDARS, they do a bunch of stuff that doesn’t scale and they have extra sensors etc., and they do mapping and all this stuff. You’re doing it at training time and then you’re distilling that into a test-time package that is deployed to the cars and is vision only. It’s like an arbitrage on sensors and expense. And so I think it’s actually kind of a brilliant strategy that I don’t think is fully appreciated, and I think is going to work out well, because the pixels have the information, and I think the network will be capable of doing that, and yes at training time I think these sensors are really useful, but I don’t think they are as useful at test time.


Do note that Karpathy — who worked at Tesla for five years — is hardly a neutral observer, and also note that he forecasts a fully neural net approach to driving as taking ten years; that’s hardly next year, as Musk promised. That end goal, though, is Level 5, with low cost sensors and thus low cost cars, the key ingredient of realizing the dream of full autonomy and the transformation that would follow.


The Cost of Dreams
I don’t, for the record, know if the Tesla approach is going to work; my experience with both Waymo and Tesla definitely makes clear that Waymo is ahead right now (and the disengagement numbers for Tesla are multiple orders of magnitude worse). Most experts assume that LiDAR sensors are non-negotiable in particular.


The Tesla bet, though, is that Waymo’s approach ultimately doesn’t scale and isn’t generalizable to true Level 5, while starting with the dream — true autonomy — leads Tesla down a better path of relying on nothing but AI, fueled by data and fine-tuning that you can only do if you already have millions of cars on the road. That is the connection to SpaceX and what happened this weekend: if you start with the dream, then understand the cost structure necessary to achieve that dream, you force yourself down the only path possible, forgoing easier solutions that don’t scale for fantastical ones that do.


________________


Section 3 - articles actually written by Matt Levine


Article 1


SEC: General
	What if the US Securities and Exchange Commission never brings another enforcement case? What if it’s like “ahh, go ahead, do all the fraud you want”? What if the only enforcement cases are against BlackRock for doing ESG investing, or against short sellers of Trump Media & Technology Group Corp.? Crime might be legal now, if you are a vocal enough supporter of Donald Trump, and the financial and crypto industries are rushing to support him. It’s hard to imagine anyone getting in trouble for texting about work from their personal phones, now.
Just in case, the SEC filed a ton of enforcement actions on Friday, the last practical day it could do so before the administration changed.[1] We will talk about a few of the highlights in the following sections.
The main reason that the SEC brings cases like these, and one of the main reasons I write about them, is that they form the contours of legal financial conduct; they tell you what you are and are not allowed to do. If there is an SEC case against a firm for doing X, then that is a way of informing the financial industry that you are not allowed to do X; each big published enforcement action expands the law a bit, telling the world not just “this firm did a bad thing” but also “this thing that a lot of people were doing? It’s bad.” Compliance officers and law firms will send out memos to their clients, saying “hey after the SEC case last week, you are not allowed to do X.” “Regulation by enforcement” is the mean way of putting it.
Last week’s cases, like every case, make rules. Or rather, made rules. They made rules that were meaningful in the world of Gary Gensler’s SEC.[2] Can you just ignore these rules now? Are they a waste of time? Are you allowed to do all of the things that last week’s cases say you are not allowed to do? Probably not, no, probably I wouldn’t go that far. Still it feels weird to talk today about what the rules are, based on last week’s cases. I’m going to do it anyway, but the rules have probably changed.


	

	

SEC: Two Sigma
	Quantitative hedge funds and proprietary trading firms employ researchers whose job is to find trading signals. A trading signal is some rule of the form “when you see X, that means that Stock Y will probably go up.” X is something observable — some other security’s price or volume or some other market event, or some accounting item, or something happening on social media, or some satellite photos of parking lots, or whatever — and the researcher has found that, when X happens, then there is statistically significant increase in the probability that Stock Y will go up. So the researcher will go to her boss and say “good news, I discovered that X predicts that Stock Y will go up, so whenever X happens we should buy some Stock Y.”
“Not so fast,” her boss will say. “You have found that, when X happens, Stock Y will outperform the market by 0.1% the next day, 54% of the time. That’s good work, and I am impressed. But we can’t run a hedge fund off that fact. For one thing, we have transaction costs to trade Stock Y, which will eat up much of the expected profit. For another thing, we have like 500 other signals that your colleagues have found. Sometimes, when your signal predicts Stock Y will go up, our other signals predict it will go down, and we should actually sell it, not buy it, if those other signals are better. Other times, when your signal predicts Stock Y will go up, our other signals also predict it will go up, so your signal is not that useful. No, we cannot run a strategy that is just ‘when X happens, buy Stock Y.’ Instead, what we will do is add your signal into our big trading model. The big trading model looks at all the signals and combines them in some appropriate way to get our firm’s combined best guess about what stocks will go up and down. Your signal will be added to the big trading model, which will make the model a bit smarter about Stock Y, some of the time. But the big trading model will never be reducible to a rule as simple as ‘when X happens, buy Stock Y.’ The big trading model knows many other things.”
And so the researcher’s signal will get added to the model. Generally speaking, the signal will be worth more — will have more influence on the model — if:
1. It is strong: “When X happens, Stock Y goes up by 5%, 90% of the time” is better than “When X happens, Stock Y goes up by 0.1%, 54% of the time.” The higher the Sharpe ratio of a strategy, the better it is.
2. It is uncorrelated to the model’s other signals. If you find a signal like “companies underperform when their chief executive officers have nice suntans,” but the model already incorporates a signal like “companies underperform when their CEOs have low golf handicaps,” and golf skill and suntans are highly correlated, then your signal is not adding very much to the model, even if it is pretty good on its own.
In fact, if your signal is too correlated to other signals, the model might ignore it or even trade against it. Michael Isichenko writes:
What is less intuitive, if the correlation of two performing books gets high enough, … the optimal weight … for the lower-Sharpe book gets negative, even though the book is profitable by itself. This observation emphasizes an important role of correlations in combining, and also poses an interesting question of pnl attribution … for the purposes of compensation of quants working for a combined portfolio. ...
Positively correlated forecasts compete for weight in the mix. Many weights can end up zero or even negative. … Forecasts contribute to the optimal bottom line in a complicated, nonlinear way, and the sum of the contributions, however computed, does not normally add up to the total. 
Isichenko is discussing the most important question in quantitative finance: “How much is my bonus?” Generally speaking, the more value a researcher adds to the overall trading model, the more she gets paid. The way you add value to the overall trading model, crudely speaking, is (1) the model trades on your signals and (2) the stocks that it buys on your signals go up.
If you are a quantitative researcher, you could imagine gaming this. One form of gaming is: 
1. You find a signal. It’s pretty good, not amazing, but pretty good.
2. You hand it off to your boss and it goes into the big trading model.
3. The big trading model doesn’t make much use of it, because it is too correlated with other signals.
4. Therefore, you do not get paid very much for the signal you found.
5. You find those other signals and break their kneecaps.
6. Now the big trading model stops using the other signals and uses yours instead.
7. Yours is pretty good, so it makes money, so you get paid.
The problem with this is that you can’t really break the kneecaps of statistical models of stock price returns. What you could do, maybe, is trick the big trading model into thinking that your signal is uncorrelated with the other signals. Then the big trading model will use your signal a lot — it will trade a lot of stock based on your signal — because uncorrelated signals are very useful. And you will get paid a lot.
Is this bad? Well, sure, I mean, the big trading model was optimized to achieve high risk-adjusted returns, and by tricking it into using more of your signal, you break that optimization. The model will achieve lower risk-adjusted returns. But maybe higher absolute returns; who knows? By breaking the model in this way, you cause it to double down on your signal, to put more money into your signal than it deserves. If your signal works pretty well, then for a while this could actually be good for the model’s performance; it is taking more risk but possibly earning higher returns.
Anyway this is not any sort of advice about anything, and in general if you are a researcher at a quant firm, tricking your firm’s trading models in this way is (1) a bad idea and (2) probably not all that feasible. They will try not to let you do that. But … maybe? Here’s an SEC case from last Thursday against Two Sigma Investments LP:
According to the SEC’s order, in or before March 2019, Two Sigma employees identified and recognized vulnerabilities in certain Two Sigma investment models that could negatively impact clients’ investment returns, but Two Sigma waited until August 2023 to address the issues. Despite recognizing these vulnerabilities, Two Sigma failed to adopt and implement written policies and procedures to address them and failed to supervise one of its employees who made unauthorized changes to more than a dozen models, which resulted in Two Sigma making investment decisions that it otherwise would not have made on behalf of its clients.
We talked about this situation in 2023, when it was first reported that “a researcher at Two Sigma Investments adjusted the hedge fund’s investing models without authorization.” Apparently he “was trying to improve the firm’s performance, which would have benefited his career and potential pay.” And, in an obvious sense, it worked: The SEC says that his “changes resulted in certain funds and [separately managed accounts] overperforming by more than $400 million and other funds and SMAs underperforming by approximately $165 million.” So he added more money than he subtracted, but in a bad way. 
The SEC order lays out the bad way. Two Sigma’s trading code was off limits to researchers: “Two Sigma’s live trading system uses Model code that is stored in a secure file called the ‘Jar,’” and researchers couldn’t mess with it. But there was a separate database, called celFS, “to store certain Model parameters that were too large to be stored in the Jar,” and the researchers had more ability to change that.[3] 
To get a signal or strategy — called a “Model” in the SEC order — approved, researchers had to submit a white paper and other documentation explaining the model, and Two Sigma decided if it was strong and uncorrelated enough. “Two Sigma management then reviewed these documents and forms, and Models could be approved where, among other things, the modeler’s documentation reported that the proposed Model’s correlation to existing Models was below a specified threshold.” 
But once it was approved:
Between November 2021 and August 2023, Modeler A, a TSI employee who had used celFS to store certain Model parameters for years, made dozens of unauthorized changes to Model decorrelation parameters stored in celFS for fourteen different Models that Two Sigma used in live trading. These Models included both Models that Modeler A developed himself as well as Models developed by Modeler A’s direct reports and with which Modeler A assisted. …
By adjusting these Model parameters, in many cases to zero (i.e., nullifying the parameter), Modeler A increased these Models’ expected correlation to Two Sigma’s other Models without detection. ...
These changes caused the Models to perform differently than expected such that Two Sigma made investment decisions that it otherwise would not have made. Specifically, Modeler A’s unauthorized changes resulted in Two Sigma buying or selling more or less of specific securities than it otherwise would have, which caused certain funds and SMAs to overperform by more than $400 million and other funds and SMAs to underperform by approximately $165 million. Modeler A received millions of dollars of additional compensation from Two Sigma as a result of the net overperformance attributable to these changes.
I think that means, roughly, that this researcher cranked up how much Two Sigma’s overall trading engine relied on his models. You have some signal, it spits out trade recommendations, and then the trading engine ignores or scales back those recommendations to the extent they correlate with the firm’s other signals. The decorrelation parameter tells the engine how much to scale them back. If you set that parameter to zero, then the engine takes more of your signal’s recommendations — even if they are highly correlated with other signals — and, if your signal is good, you get more performance attributed to you.
The business of a big quantitative hedge fund is to get a high risk-adjusted return, but in any particular year, if you are an employee of that hedge fund, you might care more about a high absolute return. Probably that gets you a bigger bonus. Quant funds aim for a low volatility of returns, but quant fund employees benefit from a high volatility: If the returns are high you get a big bonus, if they’re mediocre you need to find a new job, and if they’re catastrophic you need to find a new job, so a 50/50 chance of high or catastrophic is better, for you, than a 100% chance of mediocre.[4] If you can secretly turn the dial to take more risk, you might.
SEC: Two Sigma (2) 
	Separately, I point out occasionally that one of the great evergreen topics of recent SEC enforcement — up there with texting about work on personal cell phones — is having employees sign nondisclosure agreements. There is an SEC whistleblower protection rule saying that you are not allowed to impede anyone from talking to the SEC about possible securities law violations, “including [by] enforcing, or threatening to enforce, a confidentiality agreement,” and the SEC takes the position that even having a confidentiality agreement is a “threat” to enforce it, unless the agreement says very clearly “but of course you are allowed to talk to the SEC about whatever you want.” Many financial employers have messed this up.
And last week’s SEC case against Two Sigma also includes one of those. When employees left, they signed separation agreements, which said “but of course you are allowed to talk to the SEC,” but not in the right words:
Specifically, Section 6(d) of the Separation Agreements (the “Employee Representation”) required departing employees to make the following representation: “You represent that you have not filed against any Two Sigma Party any charges, complaints or lawsuits regarding any acts or omissions occurring prior to your execution of this Agreement with any international, federal, state, city or local court, governmental agency or arbitration tribunal.”
The Separation Agreements also contained a prospective carve-out in Section 14(c) (the “Carve Out”), which stated: “Nothing in this Agreement (including without limitations Sections 5(g), 6, 7 and 8), the Company’s policies or any other agreement between you and the Company prohibits you from making a good faith reporting of possible violations of law or regulation to any governmental agency or entity or making other disclosures that are protected under whistleblower laws or regulations.”
You might think — Two Sigma apparently did think — that this would be enough to satisfy the SEC, but it was not. I won’t tell you why not; it’s more fun to guess, or read the SEC order I guess. This stuff isn’t easy!
SEC: Startup accounting
	Roughly speaking the way it works is:
1. If you are a young startup raising a seed investment round, you can have a 6-year-old write your financial statements on a napkin and hand the napkin to potential investors and it’s fine. Like, for one thing, your financials are probably pretty simple, but also investors are not really expecting professionalism from you at this point. It’s you and two buddies in a garage, you are all working flat-out to build the product, no one expects you to do a good job keeping track of the money. The investors are investing in you, in your team and your vision and your pitch, not in the financial results you have achieved so far. If the financial statements that you gave them, on that napkin, turn out to be wrong, eh, whatever, it’s not that big a deal.
2. If you are a mature startup looking to do an initial public offering, you will have to have competent accountants prepare your financial statements, and you will have to hire a real outside auditing firm to audit them to make sure they’re right, and if you raise money in an IPO and the financial statements turn out to be wrong, you will get in trouble.
3. At some point in between those two stages, there is a transition. Before the transition, your financial statements don’t really have to be right. After the transition, they do.
This is, it should go without saying, not legal or financial advice. If you call up a lawyer or an accountant and say “hey I’m running a small startup and looking to raise money from investors, is it okay if my financial statements are slapdash and probably wrong,” they will probably say “what, no, your financial statements should be right.” Or here’s this guy:
“In our markets, when potential investors ask for and receive financial information from startups, they reasonably expect those financials to be accurate, reliable, and free from material misrepresentations and omissions,” said Mark Cave, Associate Director of the SEC’s Division of Enforcement. 
But … really? From startups? Always? Investors expect those financials to be accurate and reliable? I feel like that’s not true. I feel like the realistic expectation is more like this:
Employee A prepared the working financial information for investors on an ad-hoc basis, updating it whenever an investor requested GrubMarket’s financial information. To prepare the working financial information provided to investors, Employee A reviewed bank statements and accounting records for the wholesalers on whatever accounting systems they used and spoke with managers for the wholesalers. Employee A’s other responsibilities included overseeing operations and logistics, sourcing and packing produce, and managing payroll, human resources, insurance, and food safety. Despite GrubMarket’s rapid growth, it continued to devote limited resources to the preparation of financial information that was shared with investors.
GrubMarket Inc. was a startup founded “with the goal of digitizing the food supply chain” by “acquiring produce and meat wholesalers” and putting them on its software platform, though they continued to be managed by their former owners. It quickly succeeded in acquiring a bunch of wholesalers, each of which had different accounting systems that “ranged from QuickBooks or other accounting software to paper records.” And GrubMarket’s consolidated accounting system consisted of having one person, who was not an accountant but whose day job involved packing produce, call up the various acquired wholesalers and say “hey how much money did you make this quarter” or whatever, and then putting that in a spreadsheet or on a napkin. And then the produce packer’s spreadsheet or napkin was sent around to potential investors. Who were like “ah yes, fine, startups.”
Both of those block quotes are from an SEC enforcement action against GrubMarket Inc. from last Friday. At some level the problem is that GrubMarket sent out inaccurate financial information to investors: The SEC says that GrubMarket settled (and will pay an $8 million penalty) “for providing investors with financial information that the company should have known was unreliable and that overstated its historical revenues by approximately $550 million.” Bad!
But if you read between the lines a little bit, it seems that GrubMarket’s real problem was that it eventually hired a real chief financial officer:
In June 2019, before kicking off marketing for the Series D round, and to improve its finance function, GrubMarket hired as its Corporate Controller a certified public accountant who had an audit background. The Corporate Controller was promoted to the role of Chief Financial Officer in April 2020. …
Shortly after joining GrubMarket, the CFO determined that she could not independently verify the working financial information. Over the next eighteen months, the CFO worked with multiple third-party accounting consultants to develop a supportable and traceable set of GrubMarket financials (the “revised financial information”).
But it kept taking investor money based on the bad financials:
While GrubMarket was using the working financial information to solicit Series D investors, GrubMarket used preliminary versions of the revised financial information for other corporate purposes. …
In early February 2021, GrubMarket shared the substantially completed, revised financial information with prospective investors in the upcoming Series E round. The revised financial information showed materially lower revenue figures than were included in the working financial information that GrubMarket provided to investors in the Series D round, including to Investor A.
GrubMarket did not immediately inform Investor A of the revised financial information. As a result, when Investor A wired the $19 million Series D investment to GrubMarket in late February 2021, Investor A was unaware of the revised financial information.
I feel like the lesson here — again, not legal advice! — is that, if you are a small startup, and your operations/human resources/food safety/fruit packing manager also produces some amateur financial statements, you can send those amateur financial statements to investors, and you can take money from those investors, and if the amateur financial statements turn out to be wrong you can be like “yes but our fruit packing manager wrote them, what did you expect?” And everyone — even the SEC — will probably be like “yeah fine that’s fair.”[5] But once you hire an actual accountant to be your CFO, and she starts preparing professional financial statements, you can’t keep raising money based on the amateur ones. If you only have fake financial statements and you use them to raise money, ehh, well, you know. But once you have real financial statements you have to stop using the fake ones.

Article 2


Some good trades
	A classic way to trade bonds is that you call up a broker-dealer (generally a trader at a big bank) and say “I want to buy Bond X and I’ll pay up to 90 cents on the dollar for it,” and then the dealer thinks about who else she knows who owns Bond X and might want to sell it, and she thinks “ah yes Customer Y was telling me the other day that she wants to get rid of Bond X,” so she calls Customer Y and says “hey do you want to sell Bond X,” and the Customer Y says “sure but I won’t sell for less than 91 cents on the dollar,” and then the dealer tries to negotiate you up and/or negotiate Customer Y down so that a trade can happen. If she gets you up to 90.5, and gets Customer Y down to 90.25, then a trade will happen: The dealer will buy from Customer Y at 90.25 and sell to you at 90.5, collecting 0.25 as payment for her work.
This is not the only way for bond trades to happen — a lot of trading is electronic, and sometimes the dealer will own Bond X herself, and just sell to you out of inventory — but it is a common one. It is often called a “riskless principal” trade: The dealer buys from Customer Y for her own account, and then sells to you at a markup, but she does both trades at the same time without taking any market risk by holding the bonds.
There is no magic to these numbers, 90 and 91 or whatever. It’s sort of natural for the best bid for a bond (the highest price you, or anyone, will pay for it) to be lower than the best offer for that bond (the lowest price Customer Y, or anyone, will accept to sell it), so it takes some effort or new information to make trades happen. Your model could be “there is a market price, say 90.5, and any trades that would have happened at the market price have already happened, so anybody currently holding the bond wants more than 90.5, and anyone looking for the bond wants to pay less than 90.5” (This is a roughly plausible model of the stock market, for instance.)
It is not always true in bond markets, though, because some bonds don’t trade that often or have much in the way of a public “market price.” Many bonds — like stocks — trade electronically and frequently in markets whose prices are pretty widely visible to investors, so you (and Customer Y) might know exactly what the market prices are, but many don’t. Many trade infrequently and don’t have bid and offer prices displayed on any electronic platform. You might not know how much Bond X should cost, and Customer Y might not know how much he should ask for it. So you might call your dealer and say “I want to buy Bond X and I’ll pay up to … 95 cents?” And the dealer might call Customer Y, who might say “sure but I won’t sell for less than 88 cents.” And then there is definitely a trade!
What is the trade, though? If the dealer is acting as a fiduciary for you, she will buy the bond from Customer Y at 88 cents on the dollar and turn around and sell it to you at, say, 88.25, taking a markup of 0.25 for herself. “Good news,” she will tell you, “I got you a better price than you asked for.” On the other hand, if she is acting as a fiduciary for Customer Y, she will tell him “oh I can do better than 88, I’ll buy from you at 94.75,” and then sell to you at 95, taking 0.25 for herself. If she values you both equally, she’ll meet in the middle, buying from Customer Y at, say, 91.5 and selling to you at 91.75.
Or, you know. Or Customer Y will say “sure but I won’t sell for less than 88 cents,” and the dealer will say “man you are driving a hard bargain, my kids need to eat, but okay, fine, I think I can do 88,” and then she will call you and say “good news, it wasn’t easy, but with hard work and my excellent relationships I was able to get those bonds for you, here they are, 95 cents on the dollar just like you asked.” And she gets 7 points for herself and a round of applause from her trading desk.
In general your bond dealer, in a riskless principal trade, isn’t a fiduciary for you, and is kind of in the business of making as much money as she can on her trades, so she might be inclined to take the 7 points. But there are important constraints. Here are three:
1. You are, in this hypothetical situation, probably a professional investor, an asset manager. (The retail market is works differently.) You know all this stuff. You can just ask! The dealer will call you and say “I found those bonds for you” and you can say “well how much are you paying for them” and she will probably tell you the truth. She will tell you the truth because she wants to do repeat business with you and cares about her reputation for honesty, because she expects you’ll find out if she’s lying, and because, if she lies to you, she will get in trouble and possibly go to prison. (Not legal advice, and we have talked about cases where courts have said actually it’s okay for her to lie to you.) If she tells you that she’s paying 88, you will demand to pay 88.25, not 95.
2. There are rules — internal rules, ethical precepts, but mostly a rule of the Financial Industry Regulatory Authority (Finra) — forbidding dealers from charging “excessive markups.” Exactly what that means is a little vague, and this is not legal advice, but (1) in many markets there is a fairly standard “market” rate of markups (for instance, the 0.25 points I have used in my hypothetical examples), (2) if you regularly charge a large multiple of the market rate for ordinary transactions, you might get nervous, and (3) markups above 5% are generally assumed to be excessive. (Though “the ‘5% Policy’ is a guide, not a rule,” and “a mark-up pattern of 5% or even less may be considered unfair or unreasonable under the ‘5% Policy.’”) So the 7 points in my example is probably too much.
3. Bond prices are public, after the trade. You might not know how much you should pay for Bond X when you call your dealer. But as soon as the trade happens, the dealer generally has to report it to Finra’s Trade Reporting and Compliance Engine (Trace), which then generally publishes it. (Though the parties to the trade are anonymous.) For many types of bonds, this happens more or less immediately — within 15 minutes of the trade — so you can look, and bond investors definitely do look. The dealer will report both sides of the riskless principal trade, and if you see “Dealer buys 1,750 of Bond X at 88” followed immediately buy “Dealer sells 1,750 of Bond X at 95,” you know you got ripped off. And then you won’t trade with that dealer again. And she knows that, so she won’t rip you off.
That’s the general theory. There are exceptions. Some types of bonds don’t get reported or published immediately on Trace. For instance:
Consider, for example, Non-Agency CMO [collateralized mortgage obligations], the privately sponsored structured products based upon pools of residential mortgage collateral. The markets for such securities are illiquid and opaque. There are no price screens offering a real-time view into live quotes for the thousands of existing securities. Thus, buyers and sellers of such securities only learn the prices that bond dealers pay and receive through private disclosures from dealers. Moreover, in sharp contrast to its nearly immediate dissemination of prices from corporate bond transactions, FINRA waits more than 18 months after the trade date to release reports for CMO transactions with trade quantities greater than $1 million. After the 18-month period, the data becomes available for purchase from FINRA in quarterly releases. The absence of timely trade report dissemination in CMO means that customers have no practical way to audit dealer performance. Thus, dealers in CMO have much wider scope to profit from unfair handling of not-held customer orders than in otherwise similar Corporate bond, MBS, and ABS transactions.
If you are an investment manager and you buy a corporate bond from a dealer, you will probably look on your Bloomberg Terminal a minute later to see the trade print, and if it prints at a huge markup you will call and complain. If you buy a non-agency CMO from a dealer, will you wait 18 months, buy the quarterly data release from Finra, and scroll through it to see if your trade printed at a huge markup? That would be very cool, but no, probably not.[1] Probably you’ve forgotten the trade by then. So the dealer has more freedom to charge you whatever she wants. 
That quoted paragraph is from a paper titled “Drawing the Line between Bond Dealer and Bandit,” by Vladimir Atanasov, John Merrick and Philipp Schuster. Basically they downloaded the files and did the scrolling through them and found that, sure, dealers generally charge higher markups on CMO trades (long-delayed Trace) than on trades in corporate bonds, mortgage-backed securities and asset-backed securities (near-instant Trace):
Median markups on such transactions with market values in the $5-$10 million range for MBS and ABS are just 0.03%, comparable to the 0.02% observed for Corporate bonds. Corresponding median markups are 0.10% for Agency CMO and 0.20% for Non-Agency CMO. … The top quartile of both Agency and Non-Agency CMO riskless principal trades cross at markups above 1.0%, more than quadruple their median values.
But also they went and found a specific very cool trade:
One particular cluster of riskless principal trades stands out among the high-markup transactions. On March 25, 2020, one dealer made $54.5 million in riskless profits by buying 238 Non-Agency CMO worth $1.732 billion from a single seller, while simultaneously splitting sales of these same positions among five counterparty accounts to generate proceeds of $1.787 billion. The value-weighted average markup on this portfolio crossing trade was 3.15% (about fifteen times the full-sample median level of 0.20% for average-sized Non-Agency CMO trades).
High-fives all around! March 2020 was intense, man! The whole reason to be a bond trader at a bank is that every once in a long while there is some global catastrophe that pushes customers to buy or sell huge portfolios of bonds in a hurry, and when that happens you can charge whatever you want. You buy low, from them, and sell high, to someone else, because you sit in the middle of all the trading and the trading is wild. Banks’ trading desks make money on volatility, and this is how: This trade, in the middle of a market meltdown, apparently took the bank 12 minutes and made $54.5 million.[2]
The buyers did even better:
We interpret these trades as a stark example of a dealer who conspired with a group of “vulture” buyers to profit from a vulnerable seller. We provide benchmarks that suggest this dealer also orchestrated a price suppression of at least 20% of the fair value of this trade, benefiting the buying group while disadvantaging the seller by more than $346 million. Summing together both the price suppression and the markup effects, at least $400 million of the seller’s interests vaporized in this dealer-facilitated transaction.
Thirty-five days later, on April 29, 2020, exactly one-fifth of this same set of 238 Non-Agency CMO was “unwound” with a dealer who crossed its buy trades with matched sales to a new customer. The vulture investor received $496.8 million from the dealer upon sale of its positions, generating $139.4 million in capital gains relative to its initial investment of $357.4 million (i.e., one-fifth of $1.787 billion). The $139.4 million capital gain corresponds to a 39.0% return on invested capital in 35 days for the unwinding vulture investor
The authors think this is all bad — the buyers are “vultures” and the dealer is a “bandit” — but that’s how markets work! If you have to dump all of your bonds because the market is panicking and (1) you are also panicking and/or (2) the general panic causes you to lose your financing, someone else will probably buy those bonds from you, but they will buy them cheap. They’re buying into a panic; they want a discount. And then 35 days later when the panic is over they will make 39% on their money. Also the bank that puts the trade together will make a killing.


	

	

Private markets are the new public markets
	The core business of an investment bank is helping companies raise money by selling debt or equity. The highest-profile forms of this, traditionally, are:
1. Mergers and acquisitions (M&A), the special case of helping a company sell 100% of its equity.
2. Initial public offerings (IPOs), the special case of helping a company sell its equity to public investors for the first time.
3. Leveraged buyouts (LBOs), which are actually M&A but have the additional feature of helping the buyers of the equity sell tons of debt.
It is entirely plausible that, in 2030, the highest-profile forms will be:
1. M&A? Probably?
2. Helping big private companies sell equity, privately, to big institutional investors who are now fully comfortable investing in private companies.
3. Helping companies sell debt in the private credit markets.
And one sort of social fact in 2025 is that, if you currently run a big investment bank, a lot of your bankers grew up wanting to do M&A and IPOs and LBOs, and you have to constantly remind them, “guys, there is so much money in private markets, and the fees are great, let’s go get some of them.” 
So last month, Sujeet Indap quoted Ken Moelis’s comments about these developments:
We’re in the middle of a transaction right now. I don’t think it’s been announced or done. But it’s like $1.5 billion pref in a deal, not M&A deal, and we showed it to one of the direct lenders. That’s one of the best things we’ve ever done for them. They’re extremely happy with where they are. I think it’s a $30 — it’s $25 million to $30 million type fee. So it’s M&A type fee for coming up with a capital for the other parts of the firm. ...
I’ve been very much pushing our capital markets to make sure they’re in that [private credit] market because I think it’s going to explode and it’s not going to be easy to get the talent and get in the market and be — not every M&A adviser is interested in capital markets. Some of them just want to be M&A advisers. It’s not the same talent base to have a banker who does M&A and a banker who does capital markets. 
Or we talked this week about Goldman Sachs Group Inc. reorganizing itself to put all of the financing businesses (including sourcing private credit and private equity) in one place, because “the ability to source these private asset opportunities provides both important capital for our banking clients and unique investments for our asset and wealth management clients.” Traditionally investment bankers showed up at public companies to say “hey let’s do a merger,” and they showed up at private companies to say “hey let’s do an IPO,” and now they have to show up to say “hey let’s raise private capital.” Because that’s where a lot of the action is, and you can earn an “M&A type fee.”
Anyway I have been saying for almost a decade now that “private markets are the new public markets,” and that companies can now grow huge and become household names and raise limitless capital and provide liquidity to employees and early investors, all without going public. Here’s Goldman Chief Executive Officer David Solomon also saying it:
“Today you can get capital privately, at scale ... you can also get liquidity in the private markets. So the reasons to go public, when you really reach an incredible scale, are getting pushed out,” said Solomon at the Cisco AI Summit in Palo Alto.
“If you are running a company that’s working and it’s growing, if you take it public, it will force you to change the way to run it and you really should do that with great caution,” he added.
Goldman’s role as a trusted IPO partner has been at the core of its business for years, but that market has slowed since 2021 in response to rising interest rates. The bank is increasingly supplying its services to very large private tech companies that have pushed off public offerings.
Goldman helped Stripe raise $6.5bn in 2023, enabling the payments company to remain private for longer. Solomon said such deals were part of “a more fundamental, long-term secular trend” of shrinking numbers of public companies. ...
“It’s not fun being a public company,” said Solomon. “Who would want to be a public company?”
I think 10 years ago the CEO of Goldman Sachs would not have gone around saying, at a tech conference, that companies shouldn’t go public. Even if it was true! Goldman traditionally makes its money by taking companies public, and then by providing public-company-type investment banking services to them. But now there’s a lot of money in keeping them private too.
Hindenburg
	It seems very hard to run a short-only hedge fund? Short sellers are unpopular, so if that’s your business you will be vilified and sued and possibly arrested. Stocks mostly go up, so even if you are quite good at picking only the worst stocks to bet against, you will have a big headwind against you. Probably your best short ideas will be of the form “this company is a fraud run by evil criminals,” and if you are right, those evil criminals might do evil stuff to you. 
On the other hand, I do kind of think that we ought to be in a golden age for short-focused research? Like if your skill set is finding companies that are doing evil criminal stuff, it seems like you should have a lot of ways to monetize that skill set that didn’t exist until recently:
1. You can still do short sales with your own money, sure.
2. There are multistrategy hedge funds that run huge amounts of money and try to be market-neutral, short as much as they are long. Can’t you sell them some ideas? In some ways they are not a natural target for activist short ideas, but they do a lot of shorting and it’s worth a shot.
3. US regulators, particularly the Securities and Exchange Commission, have relatively new whistleblower reward programs that are reasonably well-oiled machines at this point and pay out huge amounts of money. If you find a big fraud at a public company, you don’t have to short the stock with your own money, or sell the idea to a hedge fund. You can sell it to the SEC, which pays top dollar. (Also the SEC doesn’t require exclusivity, so you can sell it to the hedge fund too.)
4. “Everything is securities fraud,” so if you find a fraud at a public company you can sue.[3]
Also, if your skill set is finding companies that are doing evil criminal stuff and then telling everyone about it so the stock goes down, there are a lot of ways to tell people stuff these days. Social media makes it a lot more possible for small-time researchers to publicize bad stuff that companies do, and to get attention so their stocks go down. Or, like Hunterbrook, you could start an online news site?
I am not saying that it is easy, but I am saying that it feels like a plausible path to a nice living and a fun job for the right kind of person? But:
Nate Anderson, the short seller who made his name with campaigns targeting billionaires Gautam Adani, Jack Dorsey and Carl Icahn, said he’s disbanding his small but renowned firm, Hindenburg Research.
“There is not one specific thing — no particular threat, no health issue and no big personal issue,” Anderson wrote in a letter posted on the firm’s website Wednesday. “The intensity and focus has come at the cost of missing a lot of the rest of the world and the people I care about. I now view Hindenburg as a chapter in my life, not a central thing that defines me.”
Here’s the letter, and obviously Anderson is the sort of person who enjoys this, or enjoyed it anyway:
I’m grateful for all of it. We have days of bizarre, hilarious and ridiculous stories and we’ve had a lot of fun amidst the pressure and challenges. It has been the adventure of a lifetime.
But he’s moving on, and “over the next 6 months or so I plan to work on a series of materials and videos to open-source every aspect of our model and how we conduct our investigations.” No time like the present to start your own short research firm, I guess.
Eurodollars
	My rough mental model is that “dollars” are, in essence, entries on the balance sheets of US chartered banks. If you want to transact in dollars, you need to open an account at a US bank, or at a foreign bank that has a correspondent account with a US bank. And so dollar issuance is regulated by the US Federal Reserve, and anyone who transacts anywhere in dollars is, ultimately, subject to US financial regulation. This comes up a lot when I think about sanctions, or Tether, or Tether as a tool for sanctions evasion. I wrote last year, about Tether:
Dealing in dollars means going through the regulated US financial system, and the regulated US financial system, these days, is rather hostile to certain sorts of commodities dealings. (The ones involving Russia or Venezuela.) If someone came to you with “dollars, but not through the US financial system,” you might find that appealing.
But this mental model is incomplete. Bloomberg’s Odd Lots podcast has a nice miniseries on the story of the Eurodollar, told by Lev Menand and Josh Younger, that clarified my mental model. Eurodollars are “dollars, but not through the US financial system,” dollar-denominated liabilities of foreign banks that are not necessarily backed by dollar-denominated assets. (Like Tether used to be!) Anyway it is a good series and I learned a lot; you can listen to Part 1, Part 2 and Part 3 at those links.
Things happen
	Morgan Stanley Profit Doubles With Big Stock-Trading Beat. BofA Investment Bankers Boost Earnings as Loan Income Rises. Private Equity Faces Pockets of Distress for Long-Held Assets. Pension funds dabble in crypto after massive bitcoin rally. AB InBev Faces Belgium Antitrust Probe Over Beer Sales Terms. Even Harvard M.B.A.s Are Struggling to Land Jobs.
If you'd like to get Money Stuff in handy email form, right in your inbox, please subscribe at this link. Or you can subscribe to Money Stuff and other great Bloomberg newsletters here. Thanks!
[1] I hope the biggest asset managers hire someone to do this, or automate it, and then have the portfolio managers call banks to complain on like a two-year lag. One, that is very cool, and two, you only have to do that once or twice and the bank will stop overcharging you.
[2] That’s an exaggeration. The paper says that the dealer split “sales of these same positions among five counterparty accounts during a 12-minute ‘fire sale,’” but the 12 minutes seems to be based on the Trace time stamps; presumably the bank took a bit of time to line up the counterparties before actually printing the trades. But not a ton of time, probably; that was a fast-moving market!
[3] Schematically, if you reveal the fraud and it takes $1 billion off the stock price, and you had shorted 0.1% of the stock with your own money, you’d make about $1 million. But if you partner with a law firm to bring a securities class action and recover $1 billion of damages for the stock drop, you might get … 5% of that money? Without laying out your own cash or taking market risk? Just a more capital-efficient way to profit from a stock drop.
Article 3 


ESG
	The way US federal law works is that there is are only a few federal judges in the Fort Worth Division of the US District Court for the Northern District of Texas, and they are extremely conservative.[1] The best-known is Judge Reed O’Connor, “who critics say has been a subject of ‘forum shopping’ by conservative plaintiffs seeking a sympathetic court in challenges to federal policies.” So if you have a novel, conservative legal theory, what you do is you file a lawsuit in the Fort Worth federal courthouse, and then you probably get assigned to Judge O’Connor, and he probably endorses your novel legal theory. Then maybe the other side appeals, to the US Court of Appeals for the Fifth Circuit and perhaps eventually to the US Supreme Court, but these days those courts are also quite receptive to novel, conservative legal theories, so your chances are good. 
Environmental, social and governance (ESG) investing is quite controversial now, with a lot of conservative critics. And so Judge O’Connor was naturally asked to declare that it is a violation of fiduciary duty for an investment manager to consider ESG factors in making investment decisions, and last Friday he did that. Here is the opinion. It is hard to know how seriously to take this — it could be appealed, etc. — but in general the political winds do seem to be shifting against ESG, so it’s possible that this is right and ESG is now sort of illegal. 
The case involves the 401(k) retirement savings plan of American Airlines Group Inc. American runs its 401(k) plan to allow its employees to save for retirement, and it has fiduciary duties to run the plan in the best interests of its beneficiaries. It offers employees a menu of investment options in the plan, including several index funds managed by BlackRock Inc. A pilot brought a class action complaint arguing that BlackRock does ESG, that ESG is not in the best interests of investors, and that American violated its fiduciary duty to its beneficiaries by letting BlackRock do ESG. Judge O’Connor agreed.
As far as I can tell, zero percent of American’s 401(k) assets were in ESG funds. They were in regular index funds that bought all the stocks in, say, the S&P 500 index in proportion to their index weights: They did not exclude any fossil-fuel companies or make any investing decisions based on ESG factors. Instead, the complaint was that BlackRock “pursues a pervasive ESG agenda that ‘covertly converts the [retirement] [p]lan’s core index portfolios to ESG funds.’” If you just run an index fund, but in your heart you are thinking about ESG — if you talk publicly about climate change, or vote your shares in favor of climate initiatives — that’s also illegal. 
I want to discuss two main aspects of the decision, one that is pretty wild and one that is perhaps more compelling.
First, the wild part. Judge O’Connor defines ESG to mean caring about environmental, social or governance factors for reasons other than trying to improve returns to investors:
It is important to be clear about what ESG investing actually is. The evidence and expert testimony revealed that an investment strategy assumes an ESG label when it is aimed at, in whole or in part, bringing about certain types of societal change. ...
Investing that aims to reduce material risks or increase return for the exclusive purpose of obtaining a financial benefit is not ESG investing. Consideration of material risk-and-return factors is no different than the standard investing process when both are focused on financial ends. …
ESG investing is a strategy that considers or pursues a non-pecuniary interest as an end itself rather than as a means to some financial end.
I think that virtually 100% of ESG investors would disagree with this: ESG investing is, in the standard formulation, consideration of ESG factors because you think that they are material to long-term risk-adjusted financial returns. “The world will transition away from fossil fuels, so we want energy companies to have a plan for that transition,” that sort of thing. Obviously not everyone believes that that is actually what ESG investors are up to; Judge O’Connor does not:
Simply describing an ESG consideration as a material financial consideration is not enough. There must be a sound basis for characterizing something as a financial benefit. Otherwise, anything could qualify as a financial interest and can serve as pretext for non-pecuniary interests.
Sure. And then he cites a lot of statements by BlackRock about climate change, social responsibility, etc., largely (not entirely) omitting the parts of those statements where BlackRock asserts that those factors are likely to influence long-term returns. He just doesn’t believe it; it can’t be true. “Often times, BlackRock couched its ESG investing in language that superficially pledged allegiance to an economic interest. But BlackRock never gave more than lip service to show how.” And:
The emblematic example of this is BlackRock pressuring energy companies into reducing greenhouse gas emissions and otherwise complying with a particular worldview of what it means to be a responsible company that “makes a positive contribution to society” and “benefit[s] . . . the communities in which they operate.” But what is especially problematic about this stance is revealed by the inherent conflict between an energy company that derives its profits from fossil fuels and BlackRock’s climate change expectations. Indeed, reducing greenhouse gas emissions is fatal to generating profits if fossil fuels will increase profits. This is precisely the case with Exxon: production of fossil fuels made it the leading oil company in the world. It is not possible to square this circle to conclude that BlackRock’s investment strategy “maximiz[ed] the financial benefits” to the Plan. …
This is evidence of disloyalty because it does not make any rational economic sense for a shareholder (or an investment manager on behalf of shareholders) to encourage an energy company like Exxon to act in a manner that directly undermines the company’s profits. Just as it would not make rational economic sense to act in a way that pressured Microsoft to sell less of what makes it so profitable: software and services. Or JP Morgan Chase reducing the quantity of profitable financial services. Or American providing fewer flights that it could profitably sell.
What strange examples. There is a large academic literature specifically arguing that big diversified shareholders like BlackRock pressure big airlines like American to provide fewer flights than they could profitably sell, to maximize the overall profits of the airline industry and, thus, the financial returns to those big diversified shareholders. “Should index funds be illegal,” is my shorthand for this argument, and it is most specifically about airlines cutting flights to reduce competition and increase overall profits to their shareholders, particularly BlackRock funds. “It does not make any rational economic sense for a shareholder … to encourage … American [to provide] fewer flights,” the judge asserts confidently, but meanwhile actual economists are out there saying “ahh shareholders are encouraging American to provide fewer flights, so that they can increase their returns.” 
That is probably a minority view, though. What about encouraging energy companies to cut production? Well! Well! Well! Do I have news for Judge O’Connor! We talked last month about a theory that index fund managers, specifically including BlackRock, have pressured coal companies to cut their production of coal, for environmental reasons but also because those production cuts “produced cartel-level profits for” their index funds. Much like in the previous paragraph, the theory is that diversified investors like BlackRock own big stakes in every coal company, so if they can get all of the coal companies to cut production, that will reduce the supply of coal, raise prices, and lead to monopoly profits for the big coal miners, who all have the same owners. But whereas in the previous paragraph I was citing (somewhat quirky) economists, here I am citing the official position of the state of Texas. Texas sued BlackRock (and other big investment firms) for using ESG to increase shareholder returns. Texas said, in a court filing:
As demand for the electricity Americans need to heat their homes and power their businesses has gone up, the supply of the coal used to generate that electricity has been artificially depressed—and the price has skyrocketed. Defendants have reaped the rewards of higher returns, higher fees, and higher profits …
That was an antitrust complaint, so it argues that this is bad, but as a matter of maximizing shareholder returns, “higher returns, higher fees and higher profits” are good. It is the official position of the state of Texas that ESG increases shareholder returns. Separately it is also Texas’s official position that ESG reduces returns, but there’s no obligation for the anti-ESG movement to be consistent.
It’s a strange result. A giant investment manager, with trillions of dollars under management on behalf of many sophisticated clients, with thousands of employees who are paid well and have long experience in evaluating investments, claims that it considers ESG factors because they are material to its investors’ long-term risk-adjusted financial returns. The investors, with their own money on the line, mostly seem to agree: BlackRock is the biggest money manager in the world because it has convinced the most people to give it their money. And on the other hand one judge says “lol no those factors are fake.” There is no evidence that BlackRock is lying, that its claims that ESG factors are financially important are pretextual. That’s just what the judge thinks, and he gets to decide. 
The result is apparently that investors are not allowed to consider risks if those risks are politically disfavored. If you base your investment decisions on reading financial statements or drawing lines on stock charts or tracking sunspots, a judge will not demand that you prove that those techniques lead to higher returns. But if you base your investment decisions on a theory like “climate change will lead to more forest fires that will be bad for insurance companies,” a judge will suspect that you are lying and demand that you prove it. Some kinds of risk analysis are left to the business judgment of professional investment managers. But some, now, are not.[2] 
I do want to talk about another aspect of Judge O’Connor’s decision, though. The judge found that American violated its fiduciary duty of loyalty to its beneficiaries. The point is not just “ESG is a bad way to invest”; it’s that American chose to invest its 401(k) plan in a bad way, because it had some conflict of interest, some hidden agenda, some reason to put its own interests above those of its beneficiaries.
What’s the conflict? It’s easy enough to see how you could tell a disloyalty story about BlackRock. “BlackRock’s executives like diversity and hate carbon emissions, so they put their personal social and political preferences above returns to their clients,” fine. But the pilot didn’t sue BlackRock; he sued American. What’s American’s conflict?
Well, BlackRock worked for American: American’s pension managers hired BlackRock to manage their 401(k) funds. But American also worked for BlackRock: BlackRock’s funds are American’s third-biggest shareholder, with more than 8% of the stock, and “also financed approximately $400 million of American’s corporate debt at a time when American was experiencing financing difficulties.” American’s managers, who selected BlackRock to manage the 401(k) and oversaw its work, were also well aware that they were working for BlackRock:
Defendants’ own personnel put it best when describing this “significant relationship [with] BlackRock” and “this whole ESG thing” as “circular.” It is no wonder Defendants repeatedly attempted to signal alignment with BlackRock.
You sometimes used to hear this theory, about investment managers and corporations, going the other way: “Big asset managers like BlackRock tend to support corporate management in proxy voting, because they want to win the business of managing those companies’ pension funds.” Here the theory is that, because BlackRock was one of American’s biggest shareholders, American had to defer to BlackRock and couldn’t be too critical of its 401(k) management performance.[3]
And what BlackRock wanted was ESG-iness:
For example, as a large company who consumes copious amount of fossil fuels, American was potentially susceptible to a proxy fight of its own by failing to comply with BlackRock’s climate-related demands. Defendants were not only aware, but also discussed, [BlackRock Chief Executive Officer Larry] Fink’s letters outlining BlackRock’s ESG expectations for companies of its size and describing the potential consequences that such companies would likely face should they fail to meet these demands. When [American’s Managing Director of Asset Management Ken] Menezes pointed out one of Fink’s letters in an email, he also noted that BlackRock manages “over $10 billion” of Plan assets. The only plausible explanation for supplying such context would be to underscore the importance of BlackRock and suggest there is value in meeting BlackRock’s climate demands. This motivation to please BlackRock became even clearer during [American Treasurer Meghan] Montana’s testimony. Montana noted that a failure to signal that American was actively complying with ESG disclosure requirements, for example, would potentially undermine the company’s ability to obtain billions of dollars in essential loans from BlackRock.
This all strikes me as plausible.[4] There was a time, not all that long ago, when public companies really did have to worry about ESG activism from big shareholders, particularly BlackRock. In 2021, Exxon lost a proxy fight, and several directors had to leave its board, arguably because investors like BlackRock were dissatisfied with its ESG performance.
If you worked in the management of a big gas-guzzling airline, in 2021, you really might have given some thought to “how can we make BlackRock think we are doing good ESG stuff?” (That was, after all, the point of BlackRock’s ESG activism, to push corporate managers to do ESG stuff.) Doing things like cutting emissions or using cleaner jet fuel would be the most straightforward approach, but I suppose hiring BlackRock to run your 401(k) plan and sending them nice emails saying “we agree with all the ESG stuff you’re doing” could help too. It is possible that, in 2021, corporate managers might have been afraid to be too critical of ESG. Now it’s the opposite.


	

	

Oh Robinhood
	One of the main things that a stock brokerage firm does is keep lists. The famous Grayson Moorhead Securities commercial had it right.[5] “We will make a list of our clients, and how much money each of them has given us to invest. We will keep this list in a safe place. If we have time, we will make a copy of the list, in case something happens to the first list.” Timeless principles, still relevant today.
If anything, now there are many more such requirements. You have to keep a list of your clients’ money somewhere safe; you should not accidentally delete it, or let hackers steal it. You have to know who your customers are, and make sure they are not using your brokerage for money laundering. You have to keep track of your clients’ trades, and report them to regulators when requested. You have to keep copies of some customer correspondence and other information. More recently, the US Securities and Exchange Commission has started to insist that you have all of your written business conversations on “official channels” (work email, etc.), not “unofficial channels” (WhatsApp, texting from your personal phone). And there are rules about short selling, requiring you to borrow shares before selling them short,[6] so you have to keep track of whether your clients are long or short.
Robinhood Markets Inc. is a charming stock brokerage firm in many respects, but, uh, let’s say that it comes from a different world than Grayson Moorhead. Robinhood got its start as a new kind of brokerage, one whose appeal was things like “you can trade on your phone” and “there is confetti when you do a trade,” fun entertaining stuff, not boring traditional principles like “we will keep this list in a safe place.” There is a sort of loosey-goosey sensibility that is probably helpful for some sorts of marketing, but displeasing to the SEC.
And so we have talked over the years about various ways that Robinhood has found to get in trouble: for website crashes, for misrepresenting payment for order flow, for briefly offering fake bank accounts, for not having enough capital to handle meme stock demand. None of these things strike me as particularly evil. They strike me as mostly sort of hapless, the growing pains of a young brokerage firm. Anyway here is a US Securities and Exchange Commission enforcement action against Robinhood for ... I think I count eight different list-keeping violations?
The Securities and Exchange Commission [yesterday] announced that broker-dealers Robinhood Securities LLC and Robinhood Financial LLC (collectively, Robinhood) have agreed to pay $45 million in combined civil penalties to settle a range of SEC charges arising from their brokerage operations.
A little of everything: “Robinhood failed to timely investigate suspicious transactions,” “Robinhood failed to implement adequate policies and procedures designed to protect their customers from the risk of identity theft,” “Robinhood failed to adequately address known risks posed by a cybersecurity vulnerability related to remote access to their systems,” “Robinhood had longstanding failures to maintain and preserve electronic communications,” “Robinhood failed to maintain copies of core operational databases in a manner that ensured legally required records were protected from deletion or modification for the required length of time” (don’t delete the list!), “Robinhood failed to maintain some of their communications with their brokerage customers as legally required,” “Robinhood Securities failed to provide complete and accurate securities trading information, known as blue sheet data, to the SEC,” and “in connection with its stock lending and fractional share trading programs, Robinhood Securities failed to comply with Regulation SHO, the regulatory framework designed to address abusive short selling practices.” None of it seems all that bad, honestly, but there is a lot of it.
Elsewhere in recordkeeping
	At this point I’ve said all I have to say about the SEC’s cell-phone enforcement push, but here’s another batch:
The Securities and Exchange Commission [yesterday] announced charges against nine investment advisers and three broker-dealers for failures by the firms and their personnel to maintain and preserve electronic communications, in violation of recordkeeping provisions of the federal securities laws.
Yesterday’s targets include big private equity firms (Blackstone, KKR, Apollo, Carlyle and TPG), as well as Charles Schwab, Santander and PJT Partners. 
I am putting this here for completeness, but I don’t want to talk about it. Instead let’s talk about something else. We have occasionally discussed the SEC’s fiscal year-end, which is Sept. 30. There is a paper in the Journal of Accounting and Economics about “the SEC’s September spike,” finding that the SEC rushes to complete enforcement actions in September, so that those actions can be on its list of accomplishments for the year. This is often good for the targets of these enforcement actions: If the SEC is working on a case against you, you can get a discount for agreeing to settle in September rather than waiting until the new fiscal year in October.
It is now Jan. 14. The SEC’s fiscal year-end is quite a long way away. But things will be very different at the SEC in a week. A lot of the current SEC’s enforcement priorities will no longer be priorities under the new Trump administration. Some of this is about politically charged stuff — crypto enforcement seems like it will be less of a priority, and there will be fewer greenwashing cases and maybe more greenhushing cases — but most of it probably isn’t. There is a general business triumphalism, a broad deregulatory push, a particular distaste for “regulation by enforcement,” all of which suggest that cases like this will tend to wither away. I doubt Donald Trump cares about whether private equity investors should be allowed to text each other about work from their personal cell phones, but enforcement actions like this don’t really fit with the vibes of 2025.
I do wonder what that means for incentives. If the SEC is rushing to wrap up a case against you in the next week, you might expect them to offer a big discount for settling, though that is not obvious here. (Blackstone paid $12 million.[7]) Getting a settlement this week much more effectively sends a signal like “securities laws do not allow private equity employees to text about work” than waiting until next week, when the SEC might just forget all about this.
On the other hand, just bringing a case — just filing a formal public complaint in court, without a settlement — probably binds the SEC a little bit. If it brings a lawsuit this week, the SEC is somewhat unlikely to abandon it next week; Jan. 20 is not an absolute cut-off. But if the SEC wants to make any more big regulatory moves, time is running out.
Sister-in-law insider trading
	One more SEC case from yesterday. Occasionally this column delves into anthropology, or at least, the anthropology of insider trading, or at least, jokes about the anthropology of insider trading. I once wrote:
Anthropologists find that in many cultures the uncle relationship is special and profound, freighted with tradition. It is sometimes the responsibility of the uncle to educate his nephew in the society’s values, or to conduct his initiation rites. In modern American society, on the other hand, the brother-in-law relationship seems to be particularly special. The brother-in-law’s role is to insider trade on his brother-in-law’s information. … There are as many different brother-in-law relationships as there are brothers-in-law, each with its own special characteristics, but they all traditionally involve insider trading.
But what about sisters-in-law? This one was new to me:
The Securities and Exchange Commission [yesterday] charged Alfred V. Tobia, Jr., the former president and chief investment officer (CIO) of one public company and a member of the board of another, and his sister-in-law, Elizabeth Lee, with insider trading that resulted in more than $428,000 in illegal profits. The defendants have agreed to pay more than $1.36 million to settle the charges.
What is the role of the sister-in-law in insider trading? Well! “Since approximately 2013,” says the SEC, “Lee’s primary means of support has been the income from the stocks she owns and the proceeds of stock sales,” and “most of Lee’s stock investments have been based on recommendations or other information she obtained from Tobia.” So he was more or less responsible for her finances, and you can see how he might have been tempted to give her some insider tips. For one thing, it’s more efficient to tip her off about a few mergers than it is to constantly give her well-researched legal stock advice. For example:
On August 12, 2021, at 8:42 a.m., Lee texted Tobia, “Can u advise a stock that pays a nice dividend?”
Tobia responded by texting “No,” and a few minutes later texted, “I have another name” and “Will call.”
And then he allegedly called her with a tip about a public company that his employer was looking to acquire, and she then bought the stock. She just wanted a nice dividend! But he was busy! He was working on a merger! He didn’t have time to research dividend stocks for her. He had another idea.
Video games
	If you keep your money in a bank, the bank is heavily regulated. The bank has pretty strict obligations to keep track of your money and not lose it, and to have good information security so nobody can steal it. The bank will probably use your money for its own investing purposes, but those investments are required to be prudent, and there are capital and liquidity requirements to minimize the risk that the bank won’t be able to give you back your money when you ask for it. And there is deposit insurance, so if the bank does lose your money you can get it back anyway.
If instead you put all of your money into the online currency of a video game … I don’t think that there are too many federal rules regulating the video game’s information security regimes, capital or liquidity buffers, etc.? I confess I am not an expert here, and this is neither legal nor financial nor gaming advice, but it seems right. And so if your favorite video game lets you deposit real US dollars to buy in-game gold ducats and keep them in the Goblin Bank, and the company that makes that game takes all the ducats in the Goblin Bank (kidding: all the dollars it got for ducats) and loses them day-trading single-day options (in real life), and then you try to spend your ducats in the game and/or withdraw them for dollars, and the company is like “sorry bro, ducats are gone,” then … (1) that seems like a weird but somehow plausible business model for a video game company these days, (2) probably financial regulators aren’t going to stop them before they do it and (3) probably the Federal Deposit Insurance Corp. isn’t going to bail you out after they do it. 
The natural conclusion from this, to me, is “don’t keep your money in the Goblin Bank in a video game,” which frankly strikes me as bulletproof, but I suppose I am out of touch with today’s financial and gaming world. Another possibility is “well of course US financial regulators